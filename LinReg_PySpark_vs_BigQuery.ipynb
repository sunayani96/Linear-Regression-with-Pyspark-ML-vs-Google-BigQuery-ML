{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # LINEAR REGRESSION WITH PYSPARK ML VS BIGQUERY ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OBJECTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims at exploring the differences in speed and accuracy between a linear regression model built on the 'chicago_taxi_trips' dataset available in Google BigQuery as a publicly available dataset. Basic Linear Regression with BigQuery ML will be performed and compared with Linear Regression with Pyspark ML with different number of nodes to determine how close in speed Pyspark ML can get to BigQuery ML and possibly how many worker nodes are needed for this speedup.\n",
    "\n",
    "Linear Regression in particular has been chosen as the algorithm for this project as BigQuery ML is still in its Beta phase and as of now only supports Linear Regression and Logistic Regression.\n",
    "\n",
    "### 1.1 Why is this project of interest?\n",
    "This project aims to accomplish the following along with fulfilling the objective:\n",
    "- It explores a relatively traditional way as well as a new way of performing machine learning as well as gives a taste of what BigQuery is capable of. \n",
    "- It aims to explore one of the biggest reasons to use big data technologies: speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ABOUT THE DATASET\n",
    "\n",
    "The chicago_taxi_trips dataset can be found at : `https://console.cloud.google.com/bigquery?_ga=2.237940288.-1586404566.1547810022&project=sunayani&folder&organizationId&p=bigquery-public-data&d=chicago_taxi_trips&t=taxi_trips&page=table` [25]\n",
    "\n",
    "The chicago_taxi_trips dataset is a publicly available dataset available in Google BigQuery. It contains information about taxi cab rides in the city of Chicago. The purpose of this project is to perform linear regression to predict the total trip cost using the other variables as predictors. \n",
    "\n",
    "The chicago_taxi_trips dataset consists of 23 fields and a total of 112,860,054 rows and the size of the dataset is 40.43 GB. The 23 fields of the dataset are described below:\n",
    "\n",
    "1. `unique_key`            :  STRING     : uniquely identifies each row (trip)\n",
    "2. `taxi_id`               :  STRING     : uniquely identifies each taxi\n",
    "3. `trip_start_timestamp`  :  TIMESTAMP  : Trip start time; rounded to the nearest 15 mins\n",
    "4. `trip_end_timestamp`    :  TIMESTAMP  : Trip end time; rounded to the nearest 15 mins\n",
    "5. `trip_seconds`          :  INTEGER    : Total trip time in seconds\n",
    "6. `trip_miles`            :  FLOAT      : Trip distance in miles\n",
    "7. `pickup_census_tract`   :  INTEGER    : Census tract of area where trip started. Some values missing for privacy reasons\n",
    "8. `dropoff_census_tract`  :  INTEGER    : Census tract of area where trip ended. Some values missing for privacy reasons\n",
    "9. `pickup_community_area` :  INTEGER    : Community area where the trip began\n",
    "10. `dropoff_community_area`:  INTEGER    : Community area where trip ended\n",
    "11. `fare`                  :  FLOAT      : Total basic fare of the trip\n",
    "12. `tips`                  :  FLOAT      : Total amount of tip\n",
    "13. `tolls`                 :  FLOAT      : Total toll (if any) paid\n",
    "14. `extras`                :  FLOAT      : Any other kind of extra charge paid during the trip\n",
    "15. `trip_total`            :  FLOAT      : Total payment for the trip; includes fare, tips, tolls and extras. This is the variable of interest that is going to be predicted using the Linear Regression Models\n",
    "16. `payment_type`          :  STRING     : Type of payment for the trip\n",
    "17. `company`               :  STRING     : The taxi company\n",
    "18. `pickup_latitdude`      :  FLOAT      : The latitude coordinate of the pickup_census_area (if applicable)\n",
    "19. `pickup_longitude`      :  FLOAT      : The longitude coordinate of the pickup_census_area (if applicable)\n",
    "20. `pickup_location`       :  STRING     : The coordinates of the pickup_census_area (if applicable)\n",
    "21. `dropoff_latitdude`     :  FLOAT      : The latitude coordinate of the dropoff_census_area (if applicable)\n",
    "22. `dropoff_longitude`     :  FLOAT      : The longitude coordinate of the dropoff_census_area (if applicable)\n",
    "23. `dropoff_location`      :  STRING     : The coordinates of the dropoff_census_area (if applicable)\n",
    "\n",
    "At the end, after data exploration and cleaning, the dataset that is used for linear regression is about 5.04 GB. This warrants the use of big data methods as the algorithm is quite slow, learns on a large dataset and needs speeding up. The project shows how to add nodes to the cluster to speed up the process of performing machine learning in pyspark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduction to BigQuery and BigQuery ML\n",
    "\n",
    "Google BigQuery is a data warehouse which can store massive quantities of data. It allows users to query the data and perform analytics tasks on read-only big data. Data on Google BigQuery can easily be queried using simple SQL queries using the processing power of Google's infrastructure[1]. BigQuery can run queries on billions of rows of data in a matter of seconds. \n",
    "\n",
    "Google BigQuery runs on top of Dremel i.e, it is an implementation of Google's core technologies code named 'Dremel'[2]. Dremel is Google's software for running extremely fast SQL queries on large quantities of data. The basic difference between Dremel and BigQuery is that Dremel is used by the engineers, technicians, analysts etc working at Google whereas BigQuery is a public implementation of the Dremel technology meaning it is an externalisation of Dremel that is available to the public. So, the public can harness the capabilities of Dremel using BigQuery for their big data processing requirements. \n",
    "\n",
    "Google BigQuery's Public Datasets Program houses many publicly available datasets. The dataset being used in this project is one of these datasets. BigQuery has a perpetual free tier and allows 10 GB free storage and 1 TB data querying per month. \n",
    "\n",
    "In 2018, Google announced a new feature of Google BigQuery called Google BigQuery ML. It allows users to perform Machine Learning in the BigQuery architecture itself so this means that the response time is very quick as is demonstrated in this project. As of now, BigQuery ML is still in its development Beta phase meaning that currently only Linear Regression and Logistic Regression are supported. However, BigQuery ML will go a long way to helping everyone (analysts, technicians) get into the field of Machine Learning since it uses simple SQL queries to build machine learning models and similar SQL queries for prediction and model evaluation. With BigQuery ML, the user need not have in-depth knowledge of Machine Learning in order to be able to leverage the power of machine learning in their analytics tasks. Anyone with knowlegdge of SQL can easily use BigQuery ML.[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BASIC INFORMATION ABOUT TAXICAB PRICING\n",
    "\n",
    "Taxi cab services price their services according to various different parameters:\n",
    "- Distance travelled\n",
    "- Time of the day (Rush hours are priced higher due to higher demand. This is also called surge pricing)\n",
    "- Area of travel (Cab services exploit people's power to spend and charge more in areas that are more affluent) [4] \n",
    "- Any extra charges are added to the final cost of the ride (including waiting time, toll, tips and other extra costs)\n",
    "\n",
    "Using some domain knowledge (procured using some research), the parameters that are most important for predicting the price of the cab rides are selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PROJECT APPROACH\n",
    "\n",
    "The Google BigQuery Connector for Apache Spark is used to read/write data from BigQuery[5]. This project first loads the data from BigQuery using the BigQuery Connector. Then, some basic data cleaning is performed in order to get the data into a suitable format for performing linear regression on it. Once this cleaned data is procured, linear regression in pyspark is performed four times - each time using different number of worker nodes. The time requirements of each are recorded. Also, the accuracy of the model is recorded.\n",
    "\n",
    "The data used to perform linear regression in pyspark is then loaded into BigQuery using the BigQuery Connector to perform BigQuery ML on it. The time required by BigQuery ML to perform linear regression on this data is recorded. The accuracy of this model is also recorded. \n",
    "\n",
    "Finally, the different results of linear regression in pyspark is compared with the result of linear regression using BigQuery ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. IMPLEMENTATION\n",
    "\n",
    "The following portion implements the project. Before running the following blocks of code, it is important to:\n",
    "- Create a bucket : `gsutil mb gs://sunz-bucket`\n",
    "- Initilise a dataproc cluster; add initialisation actions for the BigQuery connector : \n",
    "`gcloud dataproc clusters create sunz-cluster --bucket sunz-bucket --subnet default --zone europe-west3-a --master-machine-type n1-standard-4 --master-boot-disk-size 500 --num-workers 2 --worker-machine-type n1-standard-4 --worker-boot-disk-size 500 --image-version 1.3-deb9 --project sunayani --initialization-actions \"gs://dataproc-initialization-actions/jupyter/jupyter.sh\", \"gs://dataproc-initialization-actions/connectors/connectors.sh\" --metadata \"gcs-connector-version=1.7.0\" --metadata \"bigquery-connector-version=0.11.0\"`\n",
    "- Set up an SSH channel : `gcloud compute ssh sunz-cluster-m --project=sunayani --zone=europe-west3-a -- -D 1080 -N`\n",
    "\n",
    "- Navigate to google chrome\n",
    "- Configure the browser to run the jupyter notebook on it `chrome.exe --proxy-server=\"socks5://localhost:1080\" --user-data-dir=\"%Temp%\\sunz-cluster-m\" http://sunz-cluster-m:8088`\n",
    "\n",
    "- In the newly opened browser window, access port 8123 for the jupyter notebook like so : `http://sunz-cluster-m:8123`\n",
    "- Make sure that the Kernel is Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 LOADING THE DATA FROM BIGQUERY[6]\n",
    "The following blocks of code facilitate loading of the chicago_taxi_trips dataset from the public datasets available in Google BigQuery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-cloud-bigquery in /opt/conda/lib/python3.6/site-packages (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery) (0.29.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from google-resumable-media>=0.3.1->google-cloud-bigquery) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.5.9)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2.18.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (39.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "## install google-cloud-bigquery to be able to import bigquery from google.cloud\n",
    "!pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import bigquery\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The BigQuery client using the default GCP project details\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a reference to a new BigQuery dataset\n",
    "dataset_ref = client.dataset('chicago_taxi_trips')\n",
    "dataset = bigquery.Dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New BigQuery Dataset\n",
    "dataset = client.create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the newly created dataset, set up a reference to a table which will contain the query results\n",
    "table_ref = dataset.table('Input_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure the query job\n",
    "job_config = bigquery.QueryJobConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the destination of the query job as the table reference created above\n",
    "job_config.destination = table_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It should be noted that the following query does not consider null values for some parameters. At first glance, existence of null values at those places seem problematic (Before performing any sort of data exploration, the following variables seem to be most important to predict the total cost of the taxi ride. Other variables such as fare, tips, tolls and extras have also been included in this category of variables even though these will not be used to predict the total fare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query the chicago_taxi_trips dataset in SQL. This is the default for the BigQuery Python client library \n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "    WHERE\n",
    "        trip_start_timestamp IS NOT NULL\n",
    "        AND trip_seconds IS NOT NULL\n",
    "        AND trip_miles IS NOT NULL\n",
    "        AND pickup_community_area IS NOT NULL\n",
    "        AND dropoff_community_area IS NOT NULL\n",
    "        AND fare IS NOT NULL\n",
    "        AND tips IS NOT NULL\n",
    "        AND tolls IS NOT NULL\n",
    "        AND extras IS NOT NULL\n",
    "        AND trip_total IS NOT NULL\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND company IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing some null values, the size of the dataset is 23.42 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the query \n",
    "query_job = client.query(query, job_config=job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7ff850cb1358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wait for the query to finish\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import various libraries: datetime for timing purposes\n",
    "## SparkContext - gateway for a spark cluster\n",
    "## SparkSession - start the spark session\n",
    "from datetime import datetime\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following block of code uses cloud dataproc configurations to get the bucket and the project id \n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "bucket = spark._jsc.hadoopConfiguration().get(\"fs.gs.system.bucket\")\n",
    "project = spark._jsc.hadoopConfiguration().get(\"fs.gs.project.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new directory in the bucket. This is path from where the data transfer from BigQuery will take place\n",
    "todays_date = datetime.strftime(datetime.today(), \"%Y-%m-%d-%H-%M-%S\")\n",
    "input_directory = \"gs://{}/tmp/chicago_taxi-{}\".format(bucket, todays_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The input parameters for the configuration which is an argument for reading in data from BigQuery\n",
    "conf = {\n",
    "    # Input Parameters\n",
    "    \"mapred.bq.project.id\": project,\n",
    "    \"mapred.bq.gcs.bucket\": bucket,\n",
    "    \"mapred.bq.temp.gcs.path\": input_directory,\n",
    "    \"mapred.bq.input.project.id\": project,\n",
    "    \"mapred.bq.input.dataset.id\": \"chicago_taxi_trips\",\n",
    "    \"mapred.bq.input.table.id\": \"Input_table\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data from BigQuery to pyspark using newAPIHadoopRDD. Data is read as an RDD\n",
    "table_data = spark.sparkContext.newAPIHadoopRDD(\n",
    "    \"com.google.cloud.hadoop.io.bigquery.JsonTextBigQueryInputFormat\",\n",
    "    \"org.apache.hadoop.io.LongWritable\",\n",
    "    \"com.google.gson.JsonObject\",\n",
    "    conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the JSON strings from the RDD\n",
    "table_json = table_data.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the RDD to a pyspark dataframe\n",
    "chicago_taxi_data = spark.read.json(table_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company: string (nullable = true)\n",
      " |-- dropoff_census_tract: string (nullable = true)\n",
      " |-- dropoff_community_area: string (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- dropoff_location: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- extras: long (nullable = true)\n",
      " |-- fare: long (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- pickup_census_tract: string (nullable = true)\n",
      " |-- pickup_community_area: string (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- pickup_location: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- taxi_id: string (nullable = true)\n",
      " |-- tips: long (nullable = true)\n",
      " |-- tolls: long (nullable = true)\n",
      " |-- trip_end_timestamp: string (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_seconds: string (nullable = true)\n",
      " |-- trip_start_timestamp: string (nullable = true)\n",
      " |-- trip_total: long (nullable = true)\n",
      " |-- unique_key: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View schema of the data\n",
    "chicago_taxi_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "|company                          |dropoff_census_tract|dropoff_community_area|dropoff_latitude|dropoff_location                    |dropoff_longitude|extras|fare|payment_type|pickup_census_tract|pickup_community_area|pickup_latitude|pickup_location                    |pickup_longitude|taxi_id                                                                                                                         |tips|tolls|trip_end_timestamp     |trip_miles|trip_seconds|trip_start_timestamp   |trip_total|unique_key                              |\n",
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "|Taxi Affiliation Services        |17031062800         |6                     |41.936159071    |POINT (-87.6612652184 41.936159071) |-87.661265218    |100   |705 |Credit Card |17031062800        |6                    |41.936159071   |POINT (-87.6612652184 41.936159071)|-87.661265218   |e2a2adb656cdd474442097c794f10427171757bb6605b6b1894a47aba47363d2c73d29ad1000d65743ff83c4d5bebac9606162127998e680021a54653e4871d0|200 |0    |2014-05-10 02:30:00 UTC|1.9       |60          |2014-05-10 02:30:00 UTC|1005      |e0e86ff5d0346ea1fa4399b66e1c027563a670d5|\n",
      "|Blue Ribbon Taxi Association Inc.|17031063200         |6                     |41.938391258    |POINT (-87.6385749205 41.9383912577)|-87.63857492     |150   |1085|Credit Card |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |04029395246e38f9476ebd5271accdd06a55086b216c85544f0b52f54ba905b1503b033173a0223042a2446fb68758c3710544cba89b1240e2652acdd434c3db|250 |0    |2014-07-05 01:30:00 UTC|0.2       |900         |2014-07-05 01:15:00 UTC|1485      |e0e61619b1ccc6f4ae7d0ef72807f96b21d2ae1e|\n",
      "|Taxi Affiliation Services        |17031830600         |1                     |42.001698194    |POINT (-87.6735740325 42.0016981937)|-87.673574032    |100   |1125|Credit Card |17031830700        |3                    |41.958055933   |POINT (-87.6603894557 41.958055933)|-87.660389456   |3746c6bf2dd2a0ffdb9afadaf28397dfa672f82c08f126eefb78f49dc2cfed232315f5180e0981790a915832c082aa33fe49911ddad141212aa2f5c75a4617be|245 |0    |2014-12-01 15:30:00 UTC|0.2       |840         |2014-12-01 15:15:00 UTC|1470      |7604100a2c9af85d3636e700c2eecf2004b82133|\n",
      "|Taxi Affiliation Services        |17031832600         |7                     |41.914747305    |POINT (-87.6540070286 41.9147473049)|-87.654007029    |0     |965 |Credit Card |17031081900        |8                    |41.897983898   |POINT (-87.6414915334 41.897983898)|-87.641491533   |c8c9be174422b5d2d0961a633fa4157970bd3400f636c4093ac9565cd263dc106b76676985093b98187578502ac94f79d8e475c22c10306a24a21cf6a45a0781|200 |0    |2015-10-26 18:30:00 UTC|0.1       |1020        |2015-10-26 18:00:00 UTC|1165      |5ce04a430f658e151e69f2aebf0c91f00f468bc1|\n",
      "|Taxi Affiliation Services        |null                |31                    |41.850266366    |POINT (-87.667569312 41.8502663663) |-87.667569312    |0     |645 |Cash        |null               |31                   |41.850266366   |POINT (-87.667569312 41.8502663663)|-87.667569312   |ef04abb92ec7c63b359ee39584234d905e9e54da0dd644a6a42337848f53f7476641eeaad60e69ccfb6589a713a1022ae690e11edc726b6ffae6e9df9726f6fd|0   |0    |2015-09-03 20:30:00 UTC|1.5       |420         |2015-09-03 20:15:00 UTC|645       |d5eeb2a61517f427d3992bc7096e828ad92a1dcd|\n",
      "|Taxi Affiliation Services        |17031060400         |6                     |41.950673358    |POINT (-87.6665362813 41.9506733576)|-87.666536281    |0     |565 |Cash        |17031062500        |6                    |41.941488234   |POINT (-87.671107656 41.9414882338)|-87.671107656   |f3fce508e5374eb9efd6548de2204eec16244b45ff18f2b2707f7ea819c459c9a2654f11a9d80306249289b30d1b8ad655a18acf5800a0277a316e3096077762|0   |0    |2014-12-07 03:15:00 UTC|0.0       |240         |2014-12-07 03:15:00 UTC|565       |d5c6adc9a05781bbca4549ed034e7e12409b8ff7|\n",
      "|Dispatch Taxi Affiliation        |17031832500         |7                     |41.921877461    |POINT (-87.6640782395 41.9218774613)|-87.66407824     |100   |685 |Cash        |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |96213b45ac0c57840ec7676675c8f2a4caea942579445b3ae05eea73cca39f6b038c5ce25a7b98a280356976ddd30ee97f10df80a257ad572e3cadfedc23cd0f|0   |0    |2013-07-17 22:00:00 UTC|1.7       |420         |2013-07-17 22:00:00 UTC|785       |d6adca3154482ba39b2399374f45cbf27daa9d4d|\n",
      "|Dispatch Taxi Affiliation        |17031061800         |6                     |41.946489764    |POINT (-87.647113634 41.946489764)  |-87.647113634    |100   |385 |Cash        |17031062000        |6                    |41.942577185   |POINT (-87.6470785093 41.942577185)|-87.647078509   |a691fe3f730570f709db11561d1409e08fd20b0727c913a37d8a0c8b82ed67899618562eeed4c7c97d8bebc3f86ed2bd42c49d7fbeb6a073895a0d51fbdc2b4f|0   |0    |2013-08-18 00:45:00 UTC|0.2       |120         |2013-08-18 00:30:00 UTC|485       |d7449c51b863e1d7562354c6bbb210034feff95c|\n",
      "|Taxi Affiliation Services        |17031071100         |7                     |41.921778188    |POINT (-87.6510618838 41.9217781876)|-87.651061884    |0     |765 |Credit Card |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |0f910c215b17e38a2192157793e209b43d943a42c2421376bcf53b2b9e9bfcb580859670e2b857282573072376a216e3c61a5dd61798a8f11952b11072fcd7c2|200 |0    |2014-11-27 00:45:00 UTC|2.0       |540         |2014-11-27 00:30:00 UTC|965       |d8a5476e8508cdcfdfabf1e31b9b18b229096bd5|\n",
      "|Taxi Affiliation Services        |null                |41                    |41.794090253    |POINT (-87.592310855 41.794090253)  |-87.592310855    |0     |725 |Cash        |null               |41                   |41.794090253   |POINT (-87.592310855 41.794090253) |-87.592310855   |e60d18a367f2854569291d4b1a201ec4d9e1b0646f3f59a12d89ccb6460cc460d44e35a3e480976ca61edfe9be689ce99721390dc9484d2193aebde255cb71bd|0   |0    |2016-06-26 07:15:00 UTC|0.0       |360         |2016-06-26 07:15:00 UTC|725       |5db650f5cbff0c3a3ba95b65ef2dff007bbdfeb3|\n",
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check out the top few rows of the data\n",
    "chicago_taxi_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table name which can be used when quering the data\n",
    "chicago_taxi_data.createOrReplaceTempView(\"Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60535858"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The number of rows in the dataset\n",
    "chicago_taxi_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 DATA EXPLORATION AND DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "|company                          |dropoff_census_tract|dropoff_community_area|dropoff_latitude|dropoff_location                    |dropoff_longitude|extras|fare|payment_type|pickup_census_tract|pickup_community_area|pickup_latitude|pickup_location                    |pickup_longitude|taxi_id                                                                                                                         |tips|tolls|trip_end_timestamp     |trip_miles|trip_seconds|trip_start_timestamp   |trip_total|unique_key                              |\n",
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "|Taxi Affiliation Services        |17031062800         |6                     |41.936159071    |POINT (-87.6612652184 41.936159071) |-87.661265218    |100   |705 |Credit Card |17031062800        |6                    |41.936159071   |POINT (-87.6612652184 41.936159071)|-87.661265218   |e2a2adb656cdd474442097c794f10427171757bb6605b6b1894a47aba47363d2c73d29ad1000d65743ff83c4d5bebac9606162127998e680021a54653e4871d0|200 |0    |2014-05-10 02:30:00 UTC|1.9       |60          |2014-05-10 02:30:00 UTC|1005      |e0e86ff5d0346ea1fa4399b66e1c027563a670d5|\n",
      "|Blue Ribbon Taxi Association Inc.|17031063200         |6                     |41.938391258    |POINT (-87.6385749205 41.9383912577)|-87.63857492     |150   |1085|Credit Card |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |04029395246e38f9476ebd5271accdd06a55086b216c85544f0b52f54ba905b1503b033173a0223042a2446fb68758c3710544cba89b1240e2652acdd434c3db|250 |0    |2014-07-05 01:30:00 UTC|0.2       |900         |2014-07-05 01:15:00 UTC|1485      |e0e61619b1ccc6f4ae7d0ef72807f96b21d2ae1e|\n",
      "|Taxi Affiliation Services        |17031830600         |1                     |42.001698194    |POINT (-87.6735740325 42.0016981937)|-87.673574032    |100   |1125|Credit Card |17031830700        |3                    |41.958055933   |POINT (-87.6603894557 41.958055933)|-87.660389456   |3746c6bf2dd2a0ffdb9afadaf28397dfa672f82c08f126eefb78f49dc2cfed232315f5180e0981790a915832c082aa33fe49911ddad141212aa2f5c75a4617be|245 |0    |2014-12-01 15:30:00 UTC|0.2       |840         |2014-12-01 15:15:00 UTC|1470      |7604100a2c9af85d3636e700c2eecf2004b82133|\n",
      "|Taxi Affiliation Services        |17031832600         |7                     |41.914747305    |POINT (-87.6540070286 41.9147473049)|-87.654007029    |0     |965 |Credit Card |17031081900        |8                    |41.897983898   |POINT (-87.6414915334 41.897983898)|-87.641491533   |c8c9be174422b5d2d0961a633fa4157970bd3400f636c4093ac9565cd263dc106b76676985093b98187578502ac94f79d8e475c22c10306a24a21cf6a45a0781|200 |0    |2015-10-26 18:30:00 UTC|0.1       |1020        |2015-10-26 18:00:00 UTC|1165      |5ce04a430f658e151e69f2aebf0c91f00f468bc1|\n",
      "|Taxi Affiliation Services        |null                |31                    |41.850266366    |POINT (-87.667569312 41.8502663663) |-87.667569312    |0     |645 |Cash        |null               |31                   |41.850266366   |POINT (-87.667569312 41.8502663663)|-87.667569312   |ef04abb92ec7c63b359ee39584234d905e9e54da0dd644a6a42337848f53f7476641eeaad60e69ccfb6589a713a1022ae690e11edc726b6ffae6e9df9726f6fd|0   |0    |2015-09-03 20:30:00 UTC|1.5       |420         |2015-09-03 20:15:00 UTC|645       |d5eeb2a61517f427d3992bc7096e828ad92a1dcd|\n",
      "|Taxi Affiliation Services        |17031060400         |6                     |41.950673358    |POINT (-87.6665362813 41.9506733576)|-87.666536281    |0     |565 |Cash        |17031062500        |6                    |41.941488234   |POINT (-87.671107656 41.9414882338)|-87.671107656   |f3fce508e5374eb9efd6548de2204eec16244b45ff18f2b2707f7ea819c459c9a2654f11a9d80306249289b30d1b8ad655a18acf5800a0277a316e3096077762|0   |0    |2014-12-07 03:15:00 UTC|0.0       |240         |2014-12-07 03:15:00 UTC|565       |d5c6adc9a05781bbca4549ed034e7e12409b8ff7|\n",
      "|Dispatch Taxi Affiliation        |17031832500         |7                     |41.921877461    |POINT (-87.6640782395 41.9218774613)|-87.66407824     |100   |685 |Cash        |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |96213b45ac0c57840ec7676675c8f2a4caea942579445b3ae05eea73cca39f6b038c5ce25a7b98a280356976ddd30ee97f10df80a257ad572e3cadfedc23cd0f|0   |0    |2013-07-17 22:00:00 UTC|1.7       |420         |2013-07-17 22:00:00 UTC|785       |d6adca3154482ba39b2399374f45cbf27daa9d4d|\n",
      "|Dispatch Taxi Affiliation        |17031061800         |6                     |41.946489764    |POINT (-87.647113634 41.946489764)  |-87.647113634    |100   |385 |Cash        |17031062000        |6                    |41.942577185   |POINT (-87.6470785093 41.942577185)|-87.647078509   |a691fe3f730570f709db11561d1409e08fd20b0727c913a37d8a0c8b82ed67899618562eeed4c7c97d8bebc3f86ed2bd42c49d7fbeb6a073895a0d51fbdc2b4f|0   |0    |2013-08-18 00:45:00 UTC|0.2       |120         |2013-08-18 00:30:00 UTC|485       |d7449c51b863e1d7562354c6bbb210034feff95c|\n",
      "|Taxi Affiliation Services        |17031071100         |7                     |41.921778188    |POINT (-87.6510618838 41.9217781876)|-87.651061884    |0     |765 |Credit Card |17031241400        |24                   |41.906025969   |POINT (-87.6753116216 41.906025969)|-87.675311622   |0f910c215b17e38a2192157793e209b43d943a42c2421376bcf53b2b9e9bfcb580859670e2b857282573072376a216e3c61a5dd61798a8f11952b11072fcd7c2|200 |0    |2014-11-27 00:45:00 UTC|2.0       |540         |2014-11-27 00:30:00 UTC|965       |d8a5476e8508cdcfdfabf1e31b9b18b229096bd5|\n",
      "|Taxi Affiliation Services        |null                |41                    |41.794090253    |POINT (-87.592310855 41.794090253)  |-87.592310855    |0     |725 |Cash        |null               |41                   |41.794090253   |POINT (-87.592310855 41.794090253) |-87.592310855   |e60d18a367f2854569291d4b1a201ec4d9e1b0646f3f59a12d89ccb6460cc460d44e35a3e480976ca61edfe9be689ce99721390dc9484d2193aebde255cb71bd|0   |0    |2016-06-26 07:15:00 UTC|0.0       |360         |2016-06-26 07:15:00 UTC|725       |5db650f5cbff0c3a3ba95b65ef2dff007bbdfeb3|\n",
      "+---------------------------------+--------------------+----------------------+----------------+------------------------------------+-----------------+------+----+------------+-------------------+---------------------+---------------+-----------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------+----+-----+-----------------------+----------+------------+-----------------------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check out the top few rows of the dataset using spark.sql() \n",
    "spark.sql(\"Select * from Chicago_Taxi_Trips\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------------------------------------+\n",
      "|dropoff_latitude|dropoff_longitude|dropoff_location                    |\n",
      "+----------------+-----------------+------------------------------------+\n",
      "|41.936159071    |-87.661265218    |POINT (-87.6612652184 41.936159071) |\n",
      "|41.938391258    |-87.63857492     |POINT (-87.6385749205 41.9383912577)|\n",
      "|42.001698194    |-87.673574032    |POINT (-87.6735740325 42.0016981937)|\n",
      "|41.914747305    |-87.654007029    |POINT (-87.6540070286 41.9147473049)|\n",
      "|41.850266366    |-87.667569312    |POINT (-87.667569312 41.8502663663) |\n",
      "|41.950673358    |-87.666536281    |POINT (-87.6665362813 41.9506733576)|\n",
      "|41.921877461    |-87.66407824     |POINT (-87.6640782395 41.9218774613)|\n",
      "|41.946489764    |-87.647113634    |POINT (-87.647113634 41.946489764)  |\n",
      "|41.921778188    |-87.651061884    |POINT (-87.6510618838 41.9217781876)|\n",
      "|41.794090253    |-87.592310855    |POINT (-87.592310855 41.794090253)  |\n",
      "+----------------+-----------------+------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## It seems like dropoff_location is just a combination of dropoff_latitude and dropoff_longitude. So, dropoff_location can \n",
    "## be ignored as we do not lose any information. The same goes for pickup_latitude, pickup_longitude and pickup_location\n",
    "spark.sql(\"Select dropoff_latitude, dropoff_longitude, dropoff_location from Chicago_Taxi_Trips\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select those columns that seem important from a regression perspective\n",
    "chicago_taxi_data = spark.sql(\"Select trip_start_timestamp, \\\n",
    "trip_seconds, trip_miles, pickup_community_area, dropoff_community_area, \\\n",
    "trip_total, payment_type, company from Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data.createOrReplaceTempView(\"Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why have some variables not been considered? \n",
    "- `unique_key` : This field just identifies the unique entries in the field and will not help the linear regression model's predictions.\n",
    "- `taxi_id` : This field identifies the individual taxis. It makes more sense to build a model based on trends of different companies rather than the different taxis they own. One thing that this overlooks is the fact that every company has various classes of taxis that they offer and each type of cab has its own charges. In this case, since we are not provided the details of the cab type and only the taxi id's, the prediction will be made according to the company and not the taxi.\n",
    "- `trip_end_timetstamp` : Since we are considering the hour at which the ride is taking place and we also have a field which\n",
    "describes how much time each cab ride lasts, this column can be done away with.\n",
    "- `pickup_census_tract` and `dropoff_census_tract` : This information is missing in a few rows due to privacy reasons. Also, since we are considering the community areas of the cab rides, these columns are not required.\n",
    "- `fare`, `tips`, `tolls`, `extras` : These have been left out to prevent any chance of spurious regression. Since simply the sum of all these variables gives the trip_total, using these variables to predict the trip_total is meaningless. \n",
    "- `pickup_latitude`, `pickup_longitude`, `dropoff_latitude` and `dropoff_longitude` : Since we are considering the pickup and dropoff community areas in our analysis, there is no need to include these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following few blocks of code split the trip_start_timestamp in order to extract the trip start hour i.e, the hour at which the trip started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the trip_start_timestamp column by spaces\n",
    "chicago_taxi_data = chicago_taxi_data.withColumn(\"trip_start_timestamp\", split(\"trip_start_timestamp\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|trip_start_timestamp       |trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|trip_total|payment_type|company                          |\n",
      "+---------------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|[2014-05-10, 02:30:00, UTC]|60          |1.9       |6                    |6                     |1005      |Credit Card |Taxi Affiliation Services        |\n",
      "|[2014-07-05, 01:15:00, UTC]|900         |0.2       |24                   |6                     |1485      |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|[2014-12-01, 15:15:00, UTC]|840         |0.2       |3                    |1                     |1470      |Credit Card |Taxi Affiliation Services        |\n",
      "|[2015-10-26, 18:00:00, UTC]|1020        |0.1       |8                    |7                     |1165      |Credit Card |Taxi Affiliation Services        |\n",
      "|[2015-09-03, 20:15:00, UTC]|420         |1.5       |31                   |31                    |645       |Cash        |Taxi Affiliation Services        |\n",
      "|[2014-12-07, 03:15:00, UTC]|240         |0.0       |6                    |6                     |565       |Cash        |Taxi Affiliation Services        |\n",
      "|[2013-07-17, 22:00:00, UTC]|420         |1.7       |24                   |7                     |785       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|[2013-08-18, 00:30:00, UTC]|120         |0.2       |6                    |6                     |485       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|[2014-11-27, 00:30:00, UTC]|540         |2.0       |24                   |7                     |965       |Credit Card |Taxi Affiliation Services        |\n",
      "|[2016-06-26, 07:15:00, UTC]|360         |0.0       |41                   |41                    |725       |Cash        |Taxi Affiliation Services        |\n",
      "+---------------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the resulting dataset. Under the trip_start_timestamp column, we have a list of the date, time and timezone\n",
    "chicago_taxi_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract only the time\n",
    "chicago_taxi_data = chicago_taxi_data.withColumn('trip_start_timestamp', chicago_taxi_data[\"trip_start_timestamp\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|trip_start_timestamp|trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|trip_total|payment_type|company                          |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|02:30:00            |60          |1.9       |6                    |6                     |1005      |Credit Card |Taxi Affiliation Services        |\n",
      "|01:15:00            |900         |0.2       |24                   |6                     |1485      |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|15:15:00            |840         |0.2       |3                    |1                     |1470      |Credit Card |Taxi Affiliation Services        |\n",
      "|18:00:00            |1020        |0.1       |8                    |7                     |1165      |Credit Card |Taxi Affiliation Services        |\n",
      "|20:15:00            |420         |1.5       |31                   |31                    |645       |Cash        |Taxi Affiliation Services        |\n",
      "|03:15:00            |240         |0.0       |6                    |6                     |565       |Cash        |Taxi Affiliation Services        |\n",
      "|22:00:00            |420         |1.7       |24                   |7                     |785       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|00:30:00            |120         |0.2       |6                    |6                     |485       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|00:30:00            |540         |2.0       |24                   |7                     |965       |Credit Card |Taxi Affiliation Services        |\n",
      "|07:15:00            |360         |0.0       |41                   |41                    |725       |Cash        |Taxi Affiliation Services        |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the resulting dataset\n",
    "chicago_taxi_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the trip_start_timestamp column by :\n",
    "chicago_taxi_data = chicago_taxi_data.withColumn(\"trip_start_timestamp\", split(\"trip_start_timestamp\", \":\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|trip_start_timestamp|trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|trip_total|payment_type|company                          |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|[02, 30, 00]        |60          |1.9       |6                    |6                     |1005      |Credit Card |Taxi Affiliation Services        |\n",
      "|[01, 15, 00]        |900         |0.2       |24                   |6                     |1485      |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|[15, 15, 00]        |840         |0.2       |3                    |1                     |1470      |Credit Card |Taxi Affiliation Services        |\n",
      "|[18, 00, 00]        |1020        |0.1       |8                    |7                     |1165      |Credit Card |Taxi Affiliation Services        |\n",
      "|[20, 15, 00]        |420         |1.5       |31                   |31                    |645       |Cash        |Taxi Affiliation Services        |\n",
      "|[03, 15, 00]        |240         |0.0       |6                    |6                     |565       |Cash        |Taxi Affiliation Services        |\n",
      "|[22, 00, 00]        |420         |1.7       |24                   |7                     |785       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|[00, 30, 00]        |120         |0.2       |6                    |6                     |485       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|[00, 30, 00]        |540         |2.0       |24                   |7                     |965       |Credit Card |Taxi Affiliation Services        |\n",
      "|[07, 15, 00]        |360         |0.0       |41                   |41                    |725       |Cash        |Taxi Affiliation Services        |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the resulting dataset. Under the trip_start_timestamp column, we have a list of the hour, minute and the seconds \n",
    "chicago_taxi_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the hour\n",
    "chicago_taxi_data = chicago_taxi_data.withColumn(\"trip_start_timestamp\", chicago_taxi_data['trip_start_timestamp'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|trip_start_timestamp|trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|trip_total|payment_type|company                          |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|02                  |60          |1.9       |6                    |6                     |1005      |Credit Card |Taxi Affiliation Services        |\n",
      "|01                  |900         |0.2       |24                   |6                     |1485      |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|15                  |840         |0.2       |3                    |1                     |1470      |Credit Card |Taxi Affiliation Services        |\n",
      "|18                  |1020        |0.1       |8                    |7                     |1165      |Credit Card |Taxi Affiliation Services        |\n",
      "|20                  |420         |1.5       |31                   |31                    |645       |Cash        |Taxi Affiliation Services        |\n",
      "|03                  |240         |0.0       |6                    |6                     |565       |Cash        |Taxi Affiliation Services        |\n",
      "|22                  |420         |1.7       |24                   |7                     |785       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|00                  |120         |0.2       |6                    |6                     |485       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|00                  |540         |2.0       |24                   |7                     |965       |Credit Card |Taxi Affiliation Services        |\n",
      "|07                  |360         |0.0       |41                   |41                    |725       |Cash        |Taxi Affiliation Services        |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the resulting dataset. Finally, the trip_start_timestamp contains the hour at which the trip started\n",
    "chicago_taxi_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data.createOrReplaceTempView(\"Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The variable trip_start_timestamp is cast as an integer in order to make it easy to split the trips into different\n",
    "## time slots (done later). Similarly, the variables pickup_community_area and dropoff_community_area \n",
    "## as cast as integer in order to make it easy to group them into different area zones (done later)\n",
    "\n",
    "chicago_taxi_data2 = spark.sql(\"Select CAST(trip_start_timestamp as INT), \\\n",
    "CAST(trip_seconds as DOUBLE), trip_miles, CAST(pickup_community_area as INT), CAST(dropoff_community_area as INT),\\\n",
    "trip_total, payment_type, company from Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_start_timestamp: integer (nullable = true)\n",
      " |-- trip_seconds: double (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- pickup_community_area: integer (nullable = true)\n",
      " |-- dropoff_community_area: integer (nullable = true)\n",
      " |-- trip_total: long (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View schema of the new dataframe\n",
    "chicago_taxi_data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|trip_start_timestamp|trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|trip_total|payment_type|company                          |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "|2                   |60.0        |1.9       |6                    |6                     |1005      |Credit Card |Taxi Affiliation Services        |\n",
      "|1                   |900.0       |0.2       |24                   |6                     |1485      |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|15                  |840.0       |0.2       |3                    |1                     |1470      |Credit Card |Taxi Affiliation Services        |\n",
      "|18                  |1020.0      |0.1       |8                    |7                     |1165      |Credit Card |Taxi Affiliation Services        |\n",
      "|20                  |420.0       |1.5       |31                   |31                    |645       |Cash        |Taxi Affiliation Services        |\n",
      "|3                   |240.0       |0.0       |6                    |6                     |565       |Cash        |Taxi Affiliation Services        |\n",
      "|22                  |420.0       |1.7       |24                   |7                     |785       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|0                   |120.0       |0.2       |6                    |6                     |485       |Cash        |Dispatch Taxi Affiliation        |\n",
      "|0                   |540.0       |2.0       |24                   |7                     |965       |Credit Card |Taxi Affiliation Services        |\n",
      "|7                   |360.0       |0.0       |41                   |41                    |725       |Cash        |Taxi Affiliation Services        |\n",
      "+--------------------+------------+----------+---------------------+----------------------+----------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the new dataframe\n",
    "chicago_taxi_data2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data2.createOrReplaceTempView(\"Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will place the pickup hour into 4 different buckets according to the hour:\n",
    "- Between 6-9AM - Morning Rush Hour\n",
    "- Between 9AM-4PM - Morning Time\n",
    "- Between 4-7PM - Evening Rush Hour\n",
    "- Between 7PM-6AM - Night Time\n",
    "\n",
    "All times given are in UTC so a convenient conversion here is to just add 5 hrs to UTC to get the hours mentioned above in CDT (Central Daylight time) which is the timezone that Chicago lies in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query to perform the above-mentioned transformation.\n",
    "## NOTE: trip_total is renamed label as this is the default name of the variable to be predicted in linear\n",
    "## regression in pyspark\n",
    "\n",
    "chicago_taxi_data2 = spark.sql(\"Select CASE WHEN (trip_start_timestamp > 11 AND trip_start_timestamp <= 14) THEN 'Morning Rush' \\\n",
    "WHEN (trip_start_timestamp > 14 AND trip_start_timestamp <= 21) THEN 'Morning Time' \\\n",
    "WHEN (trip_start_timestamp > 21 OR trip_start_timestamp == 00) THEN 'Evening Rush' \\\n",
    "WHEN (trip_start_timestamp > 00 AND trip_start_timestamp <= 11) THEN 'Night Time' \\\n",
    "END as time_of_day, trip_seconds, trip_miles, pickup_community_area, dropoff_community_area,\\\n",
    "trip_total as label, payment_type, company from Chicago_Taxi_Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_of_day: string (nullable = true)\n",
      " |-- trip_seconds: double (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- pickup_community_area: integer (nullable = true)\n",
      " |-- dropoff_community_area: integer (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View schema of the new dataset\n",
    "chicago_taxi_data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+---------------------+----------------------+-----+------------+---------------------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|label|payment_type|company                          |\n",
      "+------------+------------+----------+---------------------+----------------------+-----+------------+---------------------------------+\n",
      "|Night Time  |60.0        |1.9       |6                    |6                     |1005 |Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |900.0       |0.2       |24                   |6                     |1485 |Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|Morning Time|840.0       |0.2       |3                    |1                     |1470 |Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|1020.0      |0.1       |8                    |7                     |1165 |Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|420.0       |1.5       |31                   |31                    |645  |Cash        |Taxi Affiliation Services        |\n",
      "|Night Time  |240.0       |0.0       |6                    |6                     |565  |Cash        |Taxi Affiliation Services        |\n",
      "|Evening Rush|420.0       |1.7       |24                   |7                     |785  |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|120.0       |0.2       |6                    |6                     |485  |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|540.0       |2.0       |24                   |7                     |965  |Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |360.0       |0.0       |41                   |41                    |725  |Cash        |Taxi Affiliation Services        |\n",
      "+------------+------------+----------+---------------------+----------------------+-----+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the new dataset\n",
    "chicago_taxi_data2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data2.createOrReplaceTempView(\"Chicago_Taxi_Trips2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query transforms the pickup community area and the dropoff community area according to the community area the taxi ride is taking place in. Doing a quick search in wikipedia about this[7], there are 4 main community areas in the city of Chicago: Central side, North side, West side and South side. Taxi cab companies use what is known as 'route based pricing' which is based on 'willingness to pay'. In other words, this means that the cab companies use localities to determine how much money people travelling in and around the locality can pay and use this information to set prices for different localities. People travelling in and around posh localities are more likely to be rich and will be more willing to pay higher prices than those who travel in and around poorer localities. \n",
    "\n",
    "For the purpose of this project, a simple interpretation of the above concept in the context of the data is as follows:\n",
    "1. Central - The central community area is the hub of commercial activity. \n",
    "2. North - The north area is where most of the affluent families and middle class families live. \n",
    "3. South - The south side has the biggest attractions and parks in the city. \n",
    "4. West - This area has a history with socio-economic problems.\n",
    "\n",
    "There are a total of 77 community areas in Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query to perform the above-mentioned transformation. \n",
    "## NOTE: The label column is cast as double as this is a requirement of the label column in linear regression\n",
    "## in pyspark\n",
    "\n",
    "chicago_taxi_data3 = spark.sql(\"Select time_of_day, trip_seconds, trip_miles, \\\n",
    "CASE WHEN (pickup_community_area IN (8, 32, 33)) THEN 'Central'\\\n",
    "WHEN (pickup_community_area IN (1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,76,77)) THEN 'North'\\\n",
    "WHEN (pickup_community_area >= 23 AND pickup_community_area<=31) THEN 'West'\\\n",
    "WHEN (pickup_community_area>=34 AND pickup_community_area<=75) THEN 'South'\\\n",
    "END as pickup_community_area,\\\n",
    "CASE WHEN (dropoff_community_area IN (8, 32, 33)) THEN 'Central'\\\n",
    "WHEN (dropoff_community_area IN (1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,76,77)) THEN 'North'\\\n",
    "WHEN (dropoff_community_area >= 23 AND dropoff_community_area<=31) THEN 'West'\\\n",
    "WHEN (dropoff_community_area >=34 AND dropoff_community_area<=75) THEN 'South'\\\n",
    "END as dropoff_community_area,\\\n",
    "CAST(label as DOUBLE), payment_type, company from Chicago_Taxi_Trips2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_of_day: string (nullable = true)\n",
      " |-- trip_seconds: double (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- pickup_community_area: string (nullable = true)\n",
      " |-- dropoff_community_area: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View schema of the newly created dataset\n",
    "chicago_taxi_data3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+---------------------+----------------------+------+------------+---------------------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|pickup_community_area|dropoff_community_area|label |payment_type|company                          |\n",
      "+------------+------------+----------+---------------------+----------------------+------+------------+---------------------------------+\n",
      "|Night Time  |60.0        |1.9       |North                |North                 |1005.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |900.0       |0.2       |West                 |North                 |1485.0|Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|Morning Time|840.0       |0.2       |North                |North                 |1470.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|1020.0      |0.1       |Central              |North                 |1165.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|420.0       |1.5       |West                 |West                  |645.0 |Cash        |Taxi Affiliation Services        |\n",
      "|Night Time  |240.0       |0.0       |North                |North                 |565.0 |Cash        |Taxi Affiliation Services        |\n",
      "|Evening Rush|420.0       |1.7       |West                 |North                 |785.0 |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|120.0       |0.2       |North                |North                 |485.0 |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|540.0       |2.0       |West                 |North                 |965.0 |Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |360.0       |0.0       |South                |South                 |725.0 |Cash        |Taxi Affiliation Services        |\n",
      "+------------+------------+----------+---------------------+----------------------+------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the newly created dataset\n",
    "chicago_taxi_data3.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data3.createOrReplaceTempView(\"Chicago_Taxi_Trips3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_of_day: string (nullable = true)\n",
      " |-- trip_seconds: double (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- pickup_community_area: string (nullable = true)\n",
      " |-- dropoff_community_area: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the schema of the dataset\n",
    "chicago_taxi_data3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, we will concatenate the pickup and dropoff community areas in order to be able to differentiate between different trip types based on areas travelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query to perform the above-mentioned transformation. \n",
    "\n",
    "chicago_taxi_data4 = spark.sql(\"Select time_of_day, trip_seconds, trip_miles,\\\n",
    "CONCAT(pickup_community_area,', ',dropoff_community_area) as area,\\\n",
    "label, payment_type, company from Chicago_Taxi_Trips3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+--------------+------+------------+---------------------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|area          |label |payment_type|company                          |\n",
      "+------------+------------+----------+--------------+------+------------+---------------------------------+\n",
      "|Night Time  |60.0        |1.9       |North, North  |1005.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |900.0       |0.2       |West, North   |1485.0|Credit Card |Blue Ribbon Taxi Association Inc.|\n",
      "|Morning Time|840.0       |0.2       |North, North  |1470.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|1020.0      |0.1       |Central, North|1165.0|Credit Card |Taxi Affiliation Services        |\n",
      "|Morning Time|420.0       |1.5       |West, West    |645.0 |Cash        |Taxi Affiliation Services        |\n",
      "|Night Time  |240.0       |0.0       |North, North  |565.0 |Cash        |Taxi Affiliation Services        |\n",
      "|Evening Rush|420.0       |1.7       |West, North   |785.0 |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|120.0       |0.2       |North, North  |485.0 |Cash        |Dispatch Taxi Affiliation        |\n",
      "|Evening Rush|540.0       |2.0       |West, North   |965.0 |Credit Card |Taxi Affiliation Services        |\n",
      "|Night Time  |360.0       |0.0       |South, South  |725.0 |Cash        |Taxi Affiliation Services        |\n",
      "+------------+------------+----------+--------------+------+------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the dataset\n",
    "chicago_taxi_data4.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the final dataset that will be the input for linear regression. The size of this dataset is 5.04 GB.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_of_day: string (nullable = true)\n",
      " |-- trip_seconds: double (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- area: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the schema of the dataset\n",
    "chicago_taxi_data4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned and brought down to a lower dimension, this dataset will be loaded into Google BigQuery to perform BigQuery ML on it. Side by side, Pyspark ML will also be performed on the same data. The performances of both approaches in terms of speed and accuracy will be determined and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table with the dataset created in order to run SQL queries on it\n",
    "chicago_taxi_data4.createOrReplaceTempView(\"Chicago_Taxi_Trips4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Pearson Correlation Matrix[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correlation matrix to see which explanatory variables are linked to the predictor. One should note that correlation does not imply causation but using domain knowledge, we can use this information to roughly guess which explanatory variables make sense and which do not.\n",
    "\n",
    "In this case, some reseach was carried out to find out more about cab services and how they price their rides. All decisions on explanatory variables made in this notebook have been made with this in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import various libraries that facilitate the calculation of the Correlation matrix\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a list of all the features and select all of the features including the label in order \n",
    "## to prepare the data for calculating the Correlation Matrix\n",
    "features = [\"trip_seconds\", \"trip_miles\"]\n",
    "chicago_taxi_trips_corr_data = chicago_taxi_data3.select(col(\"label\"), *features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VectorAssembler combines all columns inputted as a list into a single column. This column is a list of \n",
    "## all the values\n",
    "vector = VectorAssembler(inputCols = chicago_taxi_trips_corr_data.columns, outputCol = \"unscaled_features\")\n",
    "\n",
    "## StandardScaler takes in the list of features and outputs the list of scaled features\n",
    "scaler = StandardScaler(inputCol = \"unscaled_features\", outputCol = \"scaled_features\")\n",
    "\n",
    "## Stages for the pipeline\n",
    "stages_for_pipeline = [vector,scaler]\n",
    "        \n",
    "## Create a pipeline \n",
    "pipeline = Pipeline(stages = stages_for_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a pipeline?\n",
    "A pipeline is a sequence of stages and each stage is a Transformer or an Estimator[8]\n",
    "The pyspark.ml library at its core contains the two classes Tansformer and Estimator[9]. \n",
    "\n",
    "The **Transformer** class has .tranform() method which takes a dataframe and transforms it to another dataframe (usually the same dataframe but with a column added).\n",
    "\n",
    "The **Estimator** class has a .fit() method which takes a dataframe and returns a 'model' object. This model could be for example, a machine learning model or an indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the fit and transform methods on the dataset \n",
    "chicago_taxi_trips_corr_data_scaled = pipeline.fit(chicago_taxi_trips_corr_data).transform(chicago_taxi_trips_corr_data).select(\"scaled_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|scaled_features                                             |\n",
      "+------------------------------------------------------------+\n",
      "|[0.3185416611850243,1.040912109697699,0.4831591754860263]   |\n",
      "|[0.5707805331641159,1.040912109697699,0.0]                  |\n",
      "|[0.23782522215171498,0.6939414064651326,0.24848186167852784]|\n",
      "|[1.8175612432321975,1.7348535161628316,0.5383773669701436]  |\n",
      "|[0.28971436153027097,1.214397461313982,0.013804547871029325]|\n",
      "|[0.22629430228981365,0.9541694338895573,0.24848186167852784]|\n",
      "|[0.4511472395968896,1.5613681645465483,0.0]                 |\n",
      "|[1.2871389295847362,2.5155375984361057,0.1794591223233812]  |\n",
      "|[0.19170154270410963,0.607198730656991,0.2346773138074985]  |\n",
      "|[0.19170154270410963,0.6939414064651326,0.0]                |\n",
      "+------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the scaled features \n",
    "chicago_taxi_trips_corr_data_scaled.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the correlation matrix \n",
    "corr_matrix = Correlation.corr(chicago_taxi_trips_corr_data_scaled, \"scaled_features\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation matrix is  DenseMatrix([[1.        , 0.27528411, 0.13050196],\n",
      "             [0.27528411, 1.        , 0.31321592],\n",
      "             [0.13050196, 0.31321592, 1.        ]])\n"
     ]
    }
   ],
   "source": [
    "## Output the correlation matrix\n",
    "print(\"Pearson Correlation matrix is \", str(corr_matrix[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Pearson Correlation Matrix\n",
    "The Pearson Correlation Coefficients range from -1 to 1. The closer the value is to 1 or -1, the more the correlation. A value close to 0 indicates little to no correlation. From the Pearson Correlation matrix, we can tell that the all of the numerical variables have a positive correlation with the predictor. The correlation between trip_miles and trip_total seems quite low. However, the taxicab companies calculate the fares using distance as well as duration of travel along with a host of other variables. Thus, we will keep these variables in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 LINEAR REGRESSION\n",
    "#### Some background about Linear Regression [11]\n",
    "- Linear Regression algorithm models the linear relationship between a predictor (dependent) variable and one or more predictor (independent) variables.\n",
    "\n",
    "\n",
    "- In Linear Regression, we want to find coefficients $\\beta_1,..\\beta_n$ and intercept $\\beta_0$ such that $ y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$ such that the coefficients and the intercept corresponds to the hyperplane of best fit where $y$ is the response variable and $x_i$'s are the explanatory variables. \n",
    "\n",
    "\n",
    "- The model is usually fit using the Ordinary Least Squares (OLS) method. The OLS method aims at minimising the loss function $(y - \\beta_0 - \\sum_{i=1}^{n}\\beta_ix_i)$ but this comes at the cost of overfitting the model. Overfitting means the model gets trained too closely to the data it learns from. \n",
    "\n",
    "\n",
    "- Regularisation is a technique to avoid overfitting. We can reduce overfitting by penalising the minimisation of the loss function using regularisation methods such as the ridge and lasso regression which use the L2 and L1 norms respectively. In this project, we are using the Ridge regression algorithm which uses the L2 norm to penalise the loss function. The form of the Ridge regression is : $(y - \\beta_0 - \\sum_{i=1}^{n}\\beta_ix_i) - \\lambda\\sum_{i=1}^{p} \\beta_i^2$.\n",
    "Here, lambda is the shrinkage parameter which controls the amount of regularisation. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 LINEAR REGRESSION IN PYSPARK [12][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the Pearson Correlation Matrix itself isn't a part of the Linear Regression with Pypark ML, so we will \n",
    "not add the time for this process in the calculation of the time requirements for Pyspark ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library which facilitates the calculation of how much time goes into execution of any block of code\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Background about Linear Regression in Pyspark\n",
    "In order to run a linear regression model in pyspark, a few changes need to be made to the data:\n",
    "- **Numerical Variables** : The linear regression model that will be created here will have some interacting terms since it is a multivariate model. The numerical variables need to be standardised in order to reduce multicollinearity betweeen the interacting terms. If standarisation is not carried out, we risk missing statistically significant results as well as stand the risk of producing misleading results[14].\n",
    "\n",
    "- **Categorical Variables** : There is a need to convert the categorical variables into numerical forms in order to be able to feed these into the linear regression model (a linear regression model only takes numerical quantities as input). So, we use onehotencoding in order to transform categorical variables into a format that works better with regression algorithms[15]. In pyspark, we first need to index the categorical variables before onehotencoding them. StringIndexers will encode the string categorical columns into a column of numeric indices. Onehotencoding will map this column of numeric indices into a column of binary vectors [16].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Index and Onehotencode the categorical variables so that we can pass them into our linear regression model\n",
    "## Import various libraries that make this possible\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the library to perform linear regression\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the library for evaluating the Model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following function performs linear regression in pyspark \n",
    "def linear_regression():\n",
    "    \n",
    "    # The dataset on which linear regression is to be performed after fitting and transformation \n",
    "    chicago_taxi_data_4 = spark.sql(\"Select * from Chicago_Taxi_Trips4\")\n",
    "    \n",
    "    # 80-20 training-test split on data\n",
    "    (chicago_training, chicago_test) = chicago_taxi_data_4.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # Assemble the vector of features into a vector called features_1\n",
    "    assembler = VectorAssembler(inputCols = [\"trip_seconds\", \"trip_miles\"], outputCol = \"features_1\")\n",
    "    \n",
    "    # Scale the numerical features\n",
    "    scaler = StandardScaler(inputCol = \"features_1\", outputCol = \"standardised_features\")\n",
    "    \n",
    "    # Index the various categorical variables\n",
    "    indexer_time_of_day = StringIndexer(inputCol = \"time_of_day\", outputCol = \"indexed_time_of_day\")\n",
    "    indexer_area = StringIndexer(inputCol = \"area\", outputCol = \"indexed_area\")\n",
    "    indexer_payment_type = StringIndexer(inputCol = \"payment_type\", outputCol = \"indexed_payment_type\")\n",
    "    indexer_company = StringIndexer(inputCol = \"company\", outputCol = \"indexed_company\")\n",
    "    \n",
    "    # Onehotencode the categorical variables \n",
    "    onehotencoded = OneHotEncoderEstimator(inputCols = [\"indexed_time_of_day\",\"indexed_area\", \"indexed_payment_type\",\\\n",
    "                                             \"indexed_company\"], outputCols = [\"vector_time_of_day\",\\\n",
    "                                                                             \"vector_area\",\\\n",
    "                                                                            \"vector_payment_type\",\\\n",
    "                                                                            \"vector_company\"])\n",
    "    \n",
    "    # Assemble the vectors of the onehotencoded variables into one vector called features_2\n",
    "    assembler2 = VectorAssembler(inputCols = [\"vector_time_of_day\",\"vector_area\" ,\"vector_payment_type\",\\\n",
    "                                             \"vector_company\"], outputCol = \"features_2\")\n",
    "    \n",
    "    # Assemble the vectors of standarised_features and of features_2 into a single vector called features_out\n",
    "    assembler3 = VectorAssembler(inputCols = [\"standardised_features\", \"features_2\"], outputCol = \"features_out\")\n",
    "    \n",
    "    \n",
    "    # Perform Linear Regression using 'label' as the predicted variable and features_out as the vector of predictors.\n",
    "    # regParam is the regularisation parameter and elasticNetParam = 0 indicates L2 (Euclidean) norm.\n",
    "    linear_reg = LinearRegression(labelCol = \"label\", featuresCol = \"features_out\", regParam = 0.1, elasticNetParam= 0)\n",
    "    \n",
    "    # Apply a pipeline which pipes through the various Transformers and Estimators which will fit and tranform the data\n",
    "    pipeline = Pipeline(stages = [assembler, scaler, indexer_time_of_day, indexer_area, indexer_payment_type, indexer_company, \\\n",
    "                                 onehotencoded, assembler2, assembler3, linear_reg])\n",
    "    \n",
    "    # Use the pipeline object to fit to the training data\n",
    "    Regression_model = pipeline.fit(chicago_training)\n",
    "    \n",
    "    # Use the fitted model to tranform the dataframe, in this case to predict on the unseen test dataset\n",
    "    predictions = Regression_model.transform(chicago_test)\n",
    "    \n",
    "    # Show the predictions\n",
    "    predictions.show(10, False)\n",
    "    \n",
    "    # Show the labels and predictions\n",
    "    predictions.select(\"label\", \"prediction\").show(10, False)\n",
    "    \n",
    "    # Different evaluators of the Linear Regression Model : Root Mean Squared Error(RMSE), Mean Squared Error(MSE),\n",
    "    # Mean Absolute Error(MAE) and R-squared(R^2)\n",
    "\n",
    "    evaluator = RegressionEvaluator(labelCol = \"label\", predictionCol = \"prediction\")\n",
    "\n",
    "    RMSE = evaluator.evaluate(predictions, {evaluator.metricName : \"rmse\"})\n",
    "    MSE = evaluator.evaluate(predictions, {evaluator.metricName : \"mse\"})\n",
    "    MAE = evaluator.evaluate(predictions, {evaluator.metricName : \"mae\"})\n",
    "    R_sq = evaluator.evaluate(predictions, {evaluator.metricName : \"r2\"})\n",
    "\n",
    "    print(\"The RMSE is \", RMSE)\n",
    "    print(\"\\nThe MSE is \", MSE)\n",
    "    print(\"\\nThe MAE is \", MAE)\n",
    "    print(\"\\nR-squared is \", R_sq)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections perform linear regression in pyspark with different number of nodes using the linear_regression() function defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1.1 Linear Regression with PYSPARK ML with 2 worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------------+-----+------------+-----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|area            |label|payment_type|company                      |features_1|standardised_features|indexed_time_of_day|indexed_area|indexed_payment_type|indexed_company|vector_time_of_day|vector_area   |vector_payment_type|vector_company |features_2                   |features_out                 |prediction        |\n",
      "+------------+------------+----------+----------------+-----+------------+-----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Chicago Medallion Leasing INC|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |7.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[7],[1.0])|(144,[3,18,29],[1.0,1.0,1.0])|(146,[5,20,31],[1.0,1.0,1.0])|245.19070768799327|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Taxi Affiliation Services    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|214.52049732352725|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|101.0|Cash        |Dispatch Taxi Affiliation    |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.72127677108608|\n",
      "+------------+------------+----------+----------------+-----+------------+-----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+------------------+\n",
      "|label|prediction        |\n",
      "+-----+------------------+\n",
      "|0.0  |245.19070768799327|\n",
      "|0.0  |182.72127677108608|\n",
      "|0.0  |214.52049732352725|\n",
      "|1.0  |182.72127677108608|\n",
      "|1.0  |182.72127677108608|\n",
      "|1.0  |182.72127677108608|\n",
      "|1.0  |182.72127677108608|\n",
      "|1.0  |182.72127677108608|\n",
      "|1.0  |182.72127677108608|\n",
      "|101.0|182.72127677108608|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The RMSE is  3358.429863314811\n",
      "\n",
      "The MSE is  11279051.146804737\n",
      "\n",
      "The MAE is  327.40149611632415\n",
      "\n",
      "R-squared is  0.08332179072455759\n",
      "Time taken  5452.53808  seconds\n"
     ]
    }
   ],
   "source": [
    "## With two worker nodes\n",
    "# start time\n",
    "timestart_2nodes = datetime.datetime.now()\n",
    "\n",
    "# Perform linear regression on the dataframe\n",
    "linear_regression()\n",
    "\n",
    "# end time\n",
    "timeend_2nodes = datetime.datetime.now()\n",
    "\n",
    "# calculate the difference in times\n",
    "timediff_2nodes = (timeend_2nodes-timestart_2nodes).total_seconds()\n",
    "\n",
    "# output how much time taken\n",
    "print(\"Time taken \", str(timediff_2nodes) , \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: The label column is the true total trip cost and the prediction column is the predicted total trip cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1.2 Linear Regression with PYSPARK ML with 3 worker nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the number of workers by running the following command on the command line [17]:\n",
    "`gcloud dataproc clusters update sunz-cluster --num-workers 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------------+-----+------------+-------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|area            |label|payment_type|company                  |features_1|standardised_features|indexed_time_of_day|indexed_area|indexed_payment_type|indexed_company|vector_time_of_day|vector_area   |vector_payment_type|vector_company |features_2                   |features_out                 |prediction        |\n",
      "+------------+------------+----------+----------------+-----+------------+-------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Northwest Management LLC |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |4.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[4],[1.0])|(144,[3,18,26],[1.0,1.0,1.0])|(146,[5,20,28],[1.0,1.0,1.0])|179.6886830651863 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Taxi Affiliation Services|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|214.9337391505602 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Taxi Affiliation Services|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|214.9337391505602 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Dispute     |Northwest Management LLC |(2,[],[]) |(2,[],[])            |3.0                |0.0         |4.0                 |4.0            |(3,[],[])         |(15,[0],[1.0])|(4,[],[])          |(122,[4],[1.0])|(144,[3,26],[1.0,1.0])       |(146,[5,28],[1.0,1.0])       |230.4108798420856 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.68037840009345|\n",
      "+------------+------------+----------+----------------+-----+------------+-------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+------------------+\n",
      "|label|prediction        |\n",
      "+-----+------------------+\n",
      "|0.0  |182.68037840009345|\n",
      "|0.0  |182.68037840009345|\n",
      "|0.0  |182.68037840009345|\n",
      "|0.0  |182.68037840009345|\n",
      "|0.0  |182.68037840009345|\n",
      "|0.0  |179.6886830651863 |\n",
      "|0.0  |214.9337391505602 |\n",
      "|0.0  |214.9337391505602 |\n",
      "|0.0  |230.4108798420856 |\n",
      "|1.0  |182.68037840009345|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The RMSE is  3197.3636436675047\n",
      "\n",
      "The MSE is  10223134.269846745\n",
      "\n",
      "The MAE is  326.02517340684835\n",
      "\n",
      "R-squared is  0.09159547758561903\n",
      "Time taken  3749.824337  seconds\n"
     ]
    }
   ],
   "source": [
    "## With three worker nodes\n",
    "# start time\n",
    "timestart_3nodes = datetime.datetime.now()\n",
    "\n",
    "# Perform linear regression on the dataframe\n",
    "linear_regression()\n",
    "\n",
    "# end time\n",
    "timeend_3nodes = datetime.datetime.now()\n",
    "\n",
    "# calculate the difference in times\n",
    "timediff_3nodes = (timeend_3nodes-timestart_3nodes).total_seconds()\n",
    "\n",
    "# output how much time taken\n",
    "print(\"Time taken \", str(timediff_3nodes) , \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1.3 Linear Regression with PYSPARK ML with 4 worker nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the number of workers by running the following command on the command line :\n",
    "`gcloud dataproc clusters update sunz-cluster --num-workers 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------------+-----+------------+---------------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|area            |label|payment_type|company                          |features_1|standardised_features|indexed_time_of_day|indexed_area|indexed_payment_type|indexed_company|vector_time_of_day|vector_area   |vector_payment_type|vector_company |features_2                   |features_out                 |prediction        |\n",
      "+------------+------------+----------+----------------+-----+------------+---------------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Blue Ribbon Taxi Association Inc.|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |2.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[2],[1.0])|(144,[3,18,24],[1.0,1.0,1.0])|(146,[5,20,26],[1.0,1.0,1.0])|218.6662210086804 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Taxi Affiliation Services        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|214.33004308408294|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Dispute     |Northwest Management LLC         |(2,[],[]) |(2,[],[])            |3.0                |0.0         |4.0                 |4.0            |(3,[],[])         |(15,[0],[1.0])|(4,[],[])          |(122,[4],[1.0])|(144,[3,26],[1.0,1.0])       |(146,[5,28],[1.0,1.0])       |237.4192312396308 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation        |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|182.60708119556705|\n",
      "+------------+------------+----------+----------------+-----+------------+---------------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+------------------+\n",
      "|label|prediction        |\n",
      "+-----+------------------+\n",
      "|0.0  |218.6662210086804 |\n",
      "|0.0  |182.60708119556705|\n",
      "|0.0  |182.60708119556705|\n",
      "|0.0  |182.60708119556705|\n",
      "|0.0  |214.33004308408294|\n",
      "|0.0  |237.4192312396308 |\n",
      "|1.0  |182.60708119556705|\n",
      "|1.0  |182.60708119556705|\n",
      "|1.0  |182.60708119556705|\n",
      "|1.0  |182.60708119556705|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The RMSE is  3357.2112530964564\n",
      "\n",
      "The MSE is  11270867.39791748\n",
      "\n",
      "The MAE is  327.1860584121174\n",
      "\n",
      "R-squared is  0.08351266572249627\n",
      "Time taken  3267.031064  seconds\n"
     ]
    }
   ],
   "source": [
    "## With four worker nodes\n",
    "# start time\n",
    "timestart_4nodes = datetime.datetime.now()\n",
    "\n",
    "# Perform linear regression on the dataframe\n",
    "linear_regression()\n",
    "\n",
    "# end time\n",
    "timeend_4nodes = datetime.datetime.now()\n",
    "\n",
    "# calculate the difference in times\n",
    "timediff_4nodes = (timeend_4nodes-timestart_4nodes).total_seconds() \n",
    "\n",
    "# output how much time taken\n",
    "print(\"Time taken \", str(timediff_4nodes) , \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1.4 Linear Regression with PYSPARK ML with 5 worker nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the number of workers by running the following command on the command line :\n",
    "`gcloud dataproc clusters update sunz-cluster --num-workers 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------------+-----+------------+----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|time_of_day |trip_seconds|trip_miles|area            |label|payment_type|company                     |features_1|standardised_features|indexed_time_of_day|indexed_area|indexed_payment_type|indexed_company|vector_time_of_day|vector_area   |vector_payment_type|vector_company |features_2                   |features_out                 |prediction        |\n",
      "+------------+------------+----------+----------------+-----+------------+----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Chicago Medallion Management|(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |8.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[8],[1.0])|(144,[3,18,30],[1.0,1.0,1.0])|(146,[5,20,32],[1.0,1.0,1.0])|218.30808728638522|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|0.0  |Cash        |Taxi Affiliation Services   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|215.7537783584405 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|1.0  |Cash        |Taxi Affiliation Services   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |0.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[0],[1.0])|(144,[3,18,22],[1.0,1.0,1.0])|(146,[5,20,24],[1.0,1.0,1.0])|215.7537783584405 |\n",
      "|Evening Rush|0.0         |0.0       |Central, Central|100.0|Cash        |Dispatch Taxi Affiliation   |(2,[],[]) |(2,[],[])            |3.0                |0.0         |0.0                 |1.0            |(3,[],[])         |(15,[0],[1.0])|(4,[0],[1.0])      |(122,[1],[1.0])|(144,[3,18,23],[1.0,1.0,1.0])|(146,[5,20,25],[1.0,1.0,1.0])|183.84661453948286|\n",
      "+------------+------------+----------+----------------+-----+------------+----------------------------+----------+---------------------+-------------------+------------+--------------------+---------------+------------------+--------------+-------------------+---------------+-----------------------------+-----------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+------------------+\n",
      "|label|prediction        |\n",
      "+-----+------------------+\n",
      "|0.0  |218.30808728638522|\n",
      "|0.0  |183.84661453948286|\n",
      "|0.0  |183.84661453948286|\n",
      "|0.0  |215.7537783584405 |\n",
      "|1.0  |183.84661453948286|\n",
      "|1.0  |183.84661453948286|\n",
      "|1.0  |183.84661453948286|\n",
      "|1.0  |183.84661453948286|\n",
      "|1.0  |215.7537783584405 |\n",
      "|100.0|183.84661453948286|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The RMSE is  3270.80726536154\n",
      "\n",
      "The MSE is  10698180.167141836\n",
      "\n",
      "The MAE is  326.65487532452914\n",
      "\n",
      "R-squared is  0.08843146189673479\n",
      "Time taken  2564.736702  seconds\n"
     ]
    }
   ],
   "source": [
    "## With five worker nodes\n",
    "# start time\n",
    "timestart_5nodes = datetime.datetime.now()\n",
    "\n",
    "# Perform linear regression on the dataframe\n",
    "linear_regression()\n",
    "\n",
    "# end time\n",
    "timeend_5nodes = datetime.datetime.now()\n",
    "\n",
    "# calculate the difference in times\n",
    "timediff_5nodes = (timeend_5nodes-timestart_5nodes).total_seconds()\n",
    "\n",
    "# output how much time taken\n",
    "print(\"Time taken \", str(timediff_5nodes) , \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE : There is a quota of 5 worker nodes on my gcp account which is why the maximum number of nodes used is 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Observations\n",
    "- The model is not a good model as the R2 values are quite low and the error rates are quite high. \n",
    "- The speed of performing linear regression increases as the number of nodes increases (as expected). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 LINEAR REGRESSION IN BIGQUERY\n",
    "First, the data will be loaded into BigQuery and then Linear Regression will be performed on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 LOADING DATA INTO BIGQUERY TO PERFORM BIGQUERY ML [18][19][20][21]\n",
    "The following blocks of code load the chicago_taxi_data4 dataframe into BigQuery so that BigQuery ML can be performed on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries to load data into BigQuery\n",
    "from __future__ import absolute_import\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take the newly formed dataset and load it into google bigquery to perform bigquery ML on it\n",
    "\n",
    "# Create an output directory\n",
    "output_directory = 'gs://{}/tmp/chicago_taxi_bqml_linreg_output'.format(bucket)\n",
    "\n",
    "# Write the chicago_taxi_data3 dataframe into the output directory\n",
    "sql_context = SQLContext(spark)\n",
    "chicago_taxi_data4.write.format('json').save(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 3c12fb6e-3358-439c-b322-8a826cdc4ca1\n",
      "Job finished.\n",
      "Loaded 60535858 rows.\n"
     ]
    }
   ],
   "source": [
    "## The following block of code loads the chicago_taxi_data3 dataset in JSON format into Google BigQuery into a table called \n",
    "## chicago_taxi_bqml_data which will be under the dataset chicago_taxi_trips\n",
    "\n",
    "# Name the dataset\n",
    "dataset_id = 'chicago_taxi_trips'\n",
    "\n",
    "# Create a client and set various configurations. \n",
    "dataset_ref2 = client.dataset(dataset_id)\n",
    "job_config2 = bigquery.LoadJobConfig()\n",
    "job_config2.autodetect = True\n",
    "job_config2.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "uri = \"gs://{}/tmp/chicago_taxi_bqml_linreg_output/*.json\".format(bucket)\n",
    "\n",
    "# Object which will load the dataframe into BigQuery in JSON format\n",
    "load_job = client.load_table_from_uri(uri, dataset_ref2.table(\"chicago_taxi_bqml_data\"), job_config=job_config2)  \n",
    "\n",
    "# API request\n",
    "print(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "# Waits for table load to complete.\n",
    "load_job.result()  \n",
    "print(\"Job finished.\")\n",
    " \n",
    "# Output the number of rows of the dataset\n",
    "destination_table = client.get_table(dataset_ref2.table(\"chicago_taxi_bqml_data\"))\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Performing BIGQUERY ML\n",
    "#### Some background about linear regression in BigQuery ML\n",
    "For performing linear regression in BigQuery ML, basic knowledge of SQL is required. \n",
    "- The CREATE MODEL command creates the machine learning model. For performing linear regression, in OPTIONS, lin_reg needs to be specified. Various other parameters can be set and details about these parameters can be found at https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create. BigQuery ML doesn't require the user to onehotencode and standardise variables. This is done automatically under the hood. For more than 10,000 rows of data, BigQuery automatically uses batch gradient descent, hence for the purposes of this project, the optimize_strategy needs to be manually specified to normal_equation for normal least squares method as pyspark.ml does not have features for batch gradient descent[22]. \n",
    "- The ML.EVALUATE command evalutes the machine learning model and spits out various metrics to determine if the model is good or not. In linear regression, the results include the following : mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score and explained_variance. \n",
    "- The ML.PREDICT command is used to make predictions on the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "## Install the pandas library as this is required by BigQuery when it performs linear regression on the dataset\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the pandas library\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New BigQuery Client\n",
    "client2 = bigquery.Client(location=\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the chicago_bqml_linreg dataset and then run the following cell. \n",
    "dataset_bqml = client2.create_dataset('chicago_bqml_linreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the magic commands from the client library using %load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time start\n",
    "timestart_bqml = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "One can write SQL codes on bigquery datasets using the magic command %%bigquery. The following block of clode creates a linear regression model on the dataset using all the same parameters as linear regression in pyspark ml performed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE MODEL `chicago_bqml_linreg.chicago_bqml_linreg_model`\n",
    "OPTIONS\n",
    "  (model_type='linear_reg',\n",
    "    input_label_cols=['label'], \n",
    "    l2_reg = 0.1, optimize_strategy = 'normal_equation') AS\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "  `sunayani.chicago_taxi_trips.chicago_taxi_bqml_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code evaluates the linear regression model created above. It evaluates the model using various estimates like Mean Absolute Error, Mean Squared Error, Mean Squared Log Error, Median Absolute Error, R2 score as well as Explained Variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_squared_log_error</th>\n",
       "      <th>median_absolute_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>explained_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>326.938715</td>\n",
       "      <td>1.100230e+07</td>\n",
       "      <td>0.152093</td>\n",
       "      <td>171.005275</td>\n",
       "      <td>0.085695</td>\n",
       "      <td>0.085695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_absolute_error  mean_squared_error  mean_squared_log_error  \\\n",
       "0           326.938715        1.100230e+07                0.152093   \n",
       "\n",
       "   median_absolute_error  r2_score  explained_variance  \n",
       "0             171.005275  0.085695            0.085695  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL `chicago_bqml_linreg.chicago_bqml_linreg_model`,\n",
    "    (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      `sunayani.chicago_taxi_trips.chicago_taxi_bqml_data`\n",
    "   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following block of code makes predictions on the linear regression model and outputs the first 5000 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4250.0</td>\n",
       "      <td>6424.381901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3885.0</td>\n",
       "      <td>4486.126345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905.0</td>\n",
       "      <td>2820.887034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2575.0</td>\n",
       "      <td>2712.737688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2485.0</td>\n",
       "      <td>3147.751266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2355.0</td>\n",
       "      <td>3244.089236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3225.0</td>\n",
       "      <td>4844.899137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2965.0</td>\n",
       "      <td>3918.713675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2450.0</td>\n",
       "      <td>3176.810164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2776.130845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4345.0</td>\n",
       "      <td>4719.704975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3665.0</td>\n",
       "      <td>3723.369964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3875.0</td>\n",
       "      <td>3465.806366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5790.0</td>\n",
       "      <td>5442.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2685.0</td>\n",
       "      <td>2909.847916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4155.0</td>\n",
       "      <td>3426.512543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1905.0</td>\n",
       "      <td>2658.188040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3305.0</td>\n",
       "      <td>2842.357544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4505.0</td>\n",
       "      <td>4291.562668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2845.0</td>\n",
       "      <td>3464.892969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3660.0</td>\n",
       "      <td>3276.258687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3375.0</td>\n",
       "      <td>5234.528969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2485.0</td>\n",
       "      <td>3200.683370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2845.0</td>\n",
       "      <td>3275.555266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2905.0</td>\n",
       "      <td>4091.223529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4550.0</td>\n",
       "      <td>4725.897179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3405.0</td>\n",
       "      <td>4193.330175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>7285.746001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3725.0</td>\n",
       "      <td>4750.546145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2445.0</td>\n",
       "      <td>3346.443266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>2900.0</td>\n",
       "      <td>3488.314397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>4225.0</td>\n",
       "      <td>3728.739625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>3425.0</td>\n",
       "      <td>3182.806056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>2085.0</td>\n",
       "      <td>2765.144906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>4245.0</td>\n",
       "      <td>6298.039304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>4175.0</td>\n",
       "      <td>4588.571802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>3890.0</td>\n",
       "      <td>3512.617799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>3390.0</td>\n",
       "      <td>3432.627108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>3185.0</td>\n",
       "      <td>4297.788904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>5185.0</td>\n",
       "      <td>5344.534196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>1545.0</td>\n",
       "      <td>2405.778642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>2790.0</td>\n",
       "      <td>5034.514668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>5650.0</td>\n",
       "      <td>4419.522296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>2485.0</td>\n",
       "      <td>3267.628049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>2075.0</td>\n",
       "      <td>2780.970513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>6015.0</td>\n",
       "      <td>5049.654221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>3145.0</td>\n",
       "      <td>2671.039135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>3505.0</td>\n",
       "      <td>4377.556864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>3305.0</td>\n",
       "      <td>3849.259010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>3365.0</td>\n",
       "      <td>5273.470659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>4805.0</td>\n",
       "      <td>4094.556362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>2885.0</td>\n",
       "      <td>3420.340037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>2130.0</td>\n",
       "      <td>3107.012226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>2145.0</td>\n",
       "      <td>3047.233030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>2355.0</td>\n",
       "      <td>3314.308241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4610.0</td>\n",
       "      <td>4654.999389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4215.0</td>\n",
       "      <td>5018.626936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>5980.0</td>\n",
       "      <td>5214.472291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>3400.0</td>\n",
       "      <td>3081.830598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2875.0</td>\n",
       "      <td>3832.140289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  predicted_label\n",
       "0     4250.0      6424.381901\n",
       "1     3885.0      4486.126345\n",
       "2     1905.0      2820.887034\n",
       "3     2575.0      2712.737688\n",
       "4     2485.0      3147.751266\n",
       "5     2355.0      3244.089236\n",
       "6     3225.0      4844.899137\n",
       "7     2965.0      3918.713675\n",
       "8     2450.0      3176.810164\n",
       "9     2400.0      2776.130845\n",
       "10    4345.0      4719.704975\n",
       "11    3665.0      3723.369964\n",
       "12    3875.0      3465.806366\n",
       "13    5790.0      5442.664700\n",
       "14    2685.0      2909.847916\n",
       "15    4155.0      3426.512543\n",
       "16    1905.0      2658.188040\n",
       "17    3305.0      2842.357544\n",
       "18    4505.0      4291.562668\n",
       "19    2845.0      3464.892969\n",
       "20    3660.0      3276.258687\n",
       "21    3375.0      5234.528969\n",
       "22    2485.0      3200.683370\n",
       "23    2845.0      3275.555266\n",
       "24    2905.0      4091.223529\n",
       "25    4550.0      4725.897179\n",
       "26    3405.0      4193.330175\n",
       "27    4500.0      7285.746001\n",
       "28    3725.0      4750.546145\n",
       "29    2445.0      3346.443266\n",
       "...      ...              ...\n",
       "4970  2900.0      3488.314397\n",
       "4971  4225.0      3728.739625\n",
       "4972  3425.0      3182.806056\n",
       "4973  2085.0      2765.144906\n",
       "4974  4245.0      6298.039304\n",
       "4975  4175.0      4588.571802\n",
       "4976  3890.0      3512.617799\n",
       "4977  3390.0      3432.627108\n",
       "4978  3185.0      4297.788904\n",
       "4979  5185.0      5344.534196\n",
       "4980  1545.0      2405.778642\n",
       "4981  2790.0      5034.514668\n",
       "4982  5650.0      4419.522296\n",
       "4983  2485.0      3267.628049\n",
       "4984  2075.0      2780.970513\n",
       "4985  6015.0      5049.654221\n",
       "4986  3145.0      2671.039135\n",
       "4987  3505.0      4377.556864\n",
       "4988  3305.0      3849.259010\n",
       "4989  3365.0      5273.470659\n",
       "4990  4805.0      4094.556362\n",
       "4991  2885.0      3420.340037\n",
       "4992  2130.0      3107.012226\n",
       "4993  2145.0      3047.233030\n",
       "4994  2355.0      3314.308241\n",
       "4995  4610.0      4654.999389\n",
       "4996  4215.0      5018.626936\n",
       "4997  5980.0      5214.472291\n",
       "4998  3400.0      3081.830598\n",
       "4999  2875.0      3832.140289\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "  label, predicted_label\n",
    "FROM\n",
    "  ML.PREDICT(MODEL `chicago_bqml_linreg.chicago_bqml_linreg_model`,\n",
    "    (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      `sunayani.chicago_taxi_trips.chicago_taxi_bqml_data`\n",
    "    ))\n",
    " LIMIT 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End Time\n",
    "timeend_bqml = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the time difference\n",
    "timediff_bqml = (timeend_bqml-timestart_bqml).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken  340.760514  seconds\n"
     ]
    }
   ],
   "source": [
    "## Amount of time taken by BigQuery ML to perform linear regression\n",
    "print(\"Time taken \", str(timediff_bqml) , \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Observations\n",
    "- Poor model as suggested by low R2 value as well as high error rates.\n",
    "- Very fast results (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LINEAR REGRESSION IN PYSPARK ML VS BIGQUERY ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot compares the time taken by BigQuery ML and the time taken by different nodes in Pyspark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library matplotlib for plotting purposes [23]\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/legend.py:497: UserWarning: Unrecognized location \"upper_right\". Falling back on \"best\"; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "\n",
      "  % (loc, '\\n\\t'.join(self.codes)))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VGX6//H3nUJNQkkoISA1IlVcI6iAshbsomvB3pfVFUVZdy3rfmVRv7p+XRFX11XXFVz7z7J2BcuCIIgEpAgqKC0ShNCLlIT798c5CUNNJskwSfi8rmuumfOcds8MzJ2nnOeYuyMiIlJWCfEOQEREqhclDhERiYoSh4iIREWJQ0REoqLEISIiUVHiEBGRqChxSLVkZsPM7Ll4xxFLZnaxmY2JdxyxZGb/NbNr4h2HREeJQyqFmV1gZl+Y2UYzWx6+/q2ZWbxjq67c/Xl37x+LY5tZHzP73MzWmtkqM5toZkfE4lxS8yhxSIWZ2e+AkcD/Ac2BZsC1QG+g1l72SdxvAVZDZpYUw2OnAe8AfwMaA1nAn4EtsTqn1CxKHFIhZtYAGA781t1fdff1Hpju7he7+5Zwu1Fm9riZvWdmG4FfmtlpZjbdzNaZ2RIzGxZx3DZm5mY2yMyWmll+mKAi1TKzZ81svZl9bWY5+4izi5mNDf+6/snM7gjLa5vZw+E5loava4fr+plZnpn9IaxF5ZvZWWZ2qpl9Fx7rjohzDDOzV83s5TCmaWZ2aMT628zs+3DdHDM7O2LdFeFf/SPMbBUwLCybELGNm9m1ZjbPzFab2WPFNTozSzSzv5pZgZktMLPB4fZ7SkAHA7j7i+5e5O4/u/sYd5+5Syx/C2sk35jZ8ZHfuZk9HX4eP5rZPZF/CJjZVWY2N4zxQzNrHbHuxPB4a83sUcAi1nUws3HhugIze3lv36fEmbvroUe5H8DJQCGQVMp2o4C1BLWQBKAO0A/oFi53B34Czgq3bwM48CJQP9xuBXBCuH4YsBk4FUgE7gMm7+XcqUA+8LvwvKlAr3DdcGAy0BRoAnwO3B2u6xe+t/8BkoFfhzG8EB6jSxhDu4iYtgHnhtvfAiwAksP15wEtwvc7ENgIZIbrrgjPdQOQBNQNyyZEvA8nqCk0BA4KYzk5XHctMAdoCTQCPgq33+17AdKAlcBo4BSg0S7ri2O5OXwfA8PvrnG4/j/AE+H30hSYAvwmXHcWMB/oFL6PO4HPw3UZwLqIz+fm8DzXhOtfBP7Ijn8ffeL971uPvfx/jncAelTvB3AJsGyXss+BNcDPwDFh2Sjg2VKO9TAwInzdJvzhOyRi/QPA0+HrYcBHEes6Az/v5bgXAtP3su574NSI5ZOAheHrfuF7SAyXU8OYekVsn8uOZDeMiOQV/gDmA333cu6vgAHh6yuAxbus31Pi6BOx/ApwW/j6k+If73D5hL0ljnB9p/A7yQt/vN8CmkWcdylgEdtPAS4laIbcAtTd5fP9NHz9PnD1Lp/BJqA1cNkun4+F5y9OHM8CTwIt4/3vWo99P9RUJRW1EsiIbBJx96PdvWG4LvLf2JLIHc2sl5l9amYrzGwtwV/NGbscP3KfRQR/sRdbFvF6E1BnL00zrQgSxJ60CI+7t3OsdPei8PXP4fNPEet/BlL2FK+7byf4YWwBYGaXmdlXZrbGzNYAXdn5/e70+ezFru+5+Nwtdtl/n8dy97nufoW7twzjaEGQuIv96OGveaj4c2lNUFvIj3gfTxDUPAjXj4xYt4ogQWTtGmN4/Mg4/xBuOyVserxqX+9B4keJQypqEsFfoAPKsO2uUzG/QPCXbit3bwD8g4g271CriNcHEfwlHK0lQPu9rFtK8GNX0XMUK4nXzBIImo6Whu38TwGDgfQwsc5m5/dbkamq88Nz7RZHadz9G4LaR9eI4qzi/pNQ8eeyhOD7znD3huEjzd27hNstIaj5NIx41HX3z8MYIz8fi1x292Xu/mt3bwH8Bvi7mXUo6/uQ/UeJQyrE3dcQjMj5u5mda2YpZpZgZj0I2sD3JRVY5e6bzawncNEetvmTmdUzsy7AlUB5OkzfAZqb2U1hZ3iqmfUK170I3GlmTcwsg6A/oyLXhxxuZr8Kaz43EfzITib4LJygXwIzu5Kdf6gr6hVgiJllmVlD4Na9bWhmh5jZ78ysZbjciqC5aXLEZk2BG80s2czOI2jaes/d84ExwF/NLC38rtub2bHhfv8Abg+/r+KO9PPCde8CXSI+nxsJRuEVx3VecUzAaoLPq7i2J1WIEodUmLs/AAwlaGpYTtCU8wTBj9fn+9j1t8BwM1tP8IP9yh62GUfQ2fox8KC7R31BnLuvB04EziBo6pkH/DJcfQ8wFZgJzAKmhWXl9SZBZ/Jqgj6BX7n7NnefA/yVoIb2E0Fn/8QKnGdXTxH8oM8EpgPvEfRd7OmHdz3QC/jCghFukwlqP5Gj1r4AsoEC4F7gXHdfGa67jGCY9RyC9/kqkAng7m8AfwFeMrN14XFPCdcVEAwQuJ+gGTObnT+DI8KYNhDURIe4+4LyfRwSS7ZzM6ZI1WBmbdgxIqkwvtGUjQXDiTu4+yVVIJZTgH+4e+tSN9593ysIOqz7VHpgUiOoxiFSA5hZXQuuL0kysyzgLuCNeMclNZMSh0jNYAR9TasJmqrmEjT/iVQ6NVWJiEhUVOMQEZGoxGwitXjKyMjwNm3axDsMEZFqJTc3t8Ddm5S2XY1MHG3atGHq1KnxDkNEpFoxs0Wlb6WmKhERiZISh4iIREWJQ0REolIj+zhEpOratm0beXl5bN68Od6hHLDq1KlDy5YtSU5OLtf+Shwisl/l5eWRmppKmzZtMN2Sfr9zd1auXEleXh5t27Yt1zHUVCUi+9XmzZtJT09X0ogTMyM9Pb1CNT4lDhHZ75Q04quin78SR4TN24oY9tbXLF+ntlcRkb1R4ogwY8kaXpyymBMeGscrXy5B83iJiOxOiSNCr3bpvD+kL4c0T+MPr83k0qensGTVpniHJSLVwKhRoxg8eHClHrNNmzYUFBRU6jErgxLHLto1SeGlQUdy91ld+WrJGvqPGM+/JiygaLtqHyKyZ4WF1eJeY5VGw3H3ICHBuPTI1hx/SFPueGMWw9+Zw9szl/LAOd3JbpYa7/BEaow/v/01c5auq9Rjdm6Rxl1ndNnnNhs3buT8888nLy+PoqIi/vSnP3HrrbcycOBAPv30UwBeeOEFOnTowNtvv80999zD1q1bSU9P5/nnn6dZs2YMGzaMpUuXsnDhQjIyMujfv3/J8d99913uuece3n77bTIyMnY7/xVXXEHdunX55ptvWLRoEc888wyjR49m0qRJ9OrVi1GjRlXqZ1LZVOPYhxYN6/LMFUfw8MAeLCzYyGmPTOCRj+extXB7vEMTkQr44IMPaNGiBTNmzGD27NmcfPLJAKSlpTFlyhQGDx7MTTfdBECfPn2YPHky06dP54ILLuCBBx4oOU5ubi5vvvkmL7zwQknZG2+8wf3338977723x6RRbPXq1XzyySeMGDGCM844g5tvvpmvv/6aWbNm8dVXX8XonVcO1ThKYWacdVgWfbIz+PPbc3ho7He8NyufB87tTveWDeMdnki1VlrNIFa6devGLbfcwq233srpp59O3759AbjwwgtLnm+++WYguGBx4MCB5Ofns3Xr1p0umjvzzDOpW7duyfKnn37K1KlTGTNmDGlpafuM4YwzzsDM6NatG82aNaNbt24AdOnShYULF9KjR49Kfc+VSTWOMspIqc3fLjyMpy7LYfWmrZz12ETue28uP28tindoIhKlgw8+mNzcXLp168btt9/O8OHDgZ2vbyh+fcMNNzB48GBmzZrFE088sdOFc/Xr19/puO3atWP9+vV89913pcZQu3ZtABISEkpeFy9X9T4TJY4ondi5GWNuPpaBR7TiifE/cMrI8Uz6fmW8wxKRKCxdupR69epxySWXcMsttzBt2jQAXn755ZLno446CoC1a9eSlZUFwOjRo/d53NatW/P6669z2WWX8fXXX8fwHcSXEkc5NKibzH2/6s4L1/Riu8OFT03mjjdmsW7ztniHJiJlMGvWLHr27EmPHj249957ufPOOwHYsmULvXr1YuTIkYwYMQKAYcOGcd5559G3b9999lkU69ixI88//zznnXce33//fUzfR7xYTbzILScnx/fXHQB/3lrEQ2O/5ekJC2iaWod7z+7K8Z2a7Zdzi1RHc+fOpVOnTvEOYzfFdw4tS3KoCfb0PZhZrrvnlLavahwVVLdWIn88rTOv/7Y3Deomc/Xoqdz44nRWbtgS79BERGJCiaOS9GjVkLdv6MNNJ2Tz/ux8Thwxnje/+lHTlohUE8XXY1Sme++9lx49euz0uPfeeyv1HPGgpqoY+HbZev7w2kxmLFnD8Yc05Z6zu5LZoG7pO4ocAKpqU9WBRk1VVUzH5qm8ft3R3HlaJyZ+X8CJD43n+S8WsV3TlohIDaDEESOJCcY1fdsx5qZj6d6yAX98YzYX/XMyCws2xjs0EZEKiWniMLOFZjbLzL4ys6lhWWMzG2tm88LnRmG5mdkjZjbfzGaa2S8ijnN5uP08M7s8ljFXtoPS6/H8Nb34yznd+HrpOk56eDxPjv+ewiJNWyIi1dP+qHH80t17RLSb3QZ87O7ZwMfhMsApQHb4GAQ8DkGiAe4CegE9gbuKk011YWYMPOIgPhp6LMcc3IT/fe8bfvX458zNr9zJ3URE9od4NFUNAIovvxwNnBVR/qwHJgMNzSwTOAkY6+6r3H01MBY4eX8HXRmapdXhyUsP59GLDuPH1T9zxt8m8NCYb9lSqGlLRPanhQsX0rVr193Kr7nmGubMmROHiGInJSWl0o8Z68ThwBgzyzWzQWFZM3fPBwifm4blWcCSiH3zwrK9le/EzAaZ2VQzm7pixYpKfhuVx8w4vXsLPhp6LGce2oJHPpnPaY9MIHfR6niHJnLA++c//0nnzp3jcu6qPj9VpFjPjtvb3ZeaWVNgrJl9s49t93T3dN9H+c4F7k8CT0IwHLc8we5PjerX4qGBPTijRwv++Poszv3H51xxdBt+f1JH6tXSpMVygHj/Nlg2q3KP2bwbnHJ/qZsVFhZy+eWXM336dA4++GCeffZZTj31VB588EFycnJ4+umn+ctf/kKLFi3Izs6mdu3aPProoyxYsICLLrqIwsJCTj75ZEaMGMGGDRv473//y4MPPsg777wDwODBg8nJyeGKK64gNzeXoUOHsmHDBjIyMhg1ahSZmZn069ePo48+mokTJ3LccccxatQovvvuO5KTk1m3bh3du3dn3rx5JCcn7xZ/v379OOyww8jNzWXFihU8++yz3HfffcyaNYuBAwdyzz33VO7nGiGmNQ53Xxo+LwfeIOij+ClsgiJ8Xh5unge0iti9JbB0H+U1wi87NmXM0GO59MjWPDNxIf1HjGfCvKp3q0iRmubbb79l0KBBzJw5k7S0NP7+97+XrFu6dCl33303kydPZuzYsXzzzY6/eYcMGcJ1113Hl19+SfPmzUs9z7Zt27jhhht49dVXyc3N5aqrruKPf/xjyfo1a9Ywbtw47rrrLvr168e7774LwEsvvcQ555yzx6RRrFatWowfP55rr72WAQMG8NhjjzF79mxGjRrFypWxm3w1Zn/amll9IMHd14ev+wPDgbeAy4H7w+c3w13eAgab2UsEHeFr3T3fzD4E/jeiQ7w/cHus4o6HlNpJDB/QldO7t+C212ZyydNfcH5OS/54amca1Nv7PxqRaq8MNYNYadWqFb179wbgkksu4ZFHHilZN2XKFI499lgaN24MwHnnnVcyVfrEiRN57bXXALj00ku59dZb93meb7/9ltmzZ3PiiScCUFRURGZmZsn6gQMHlry+5ppreOCBBzjrrLN45plneOqpp/Z57DPPPBMI7i/SpUuXkuO2a9eOJUuWkJ6eXvoHUQ6xbBNpBrwRzmmfBLzg7h+Y2ZfAK2Z2NbAYOC/c/j3gVGA+sAm4EsDdV5nZ3cCX4XbD3X1VDOOOm55tG/PekL6M/HgeT47/gU+/XcHdA7pyctfS/6oRkehE3ntj1+XSZtTYdV+ApKQktm/fMcy++L4d7k6XLl2YNGnSHo8VeU+P3r17s3DhQsaNG0dRUdEeO/AjxeueHjFrqnL3H9z90PDRxd3vDctXuvvx7p4dPq8Ky93dr3f39u7ezd2nRhzrX+7eIXw8E6uYq4I6yYncevIhvHl9b5qk1Oba53K5/vlprFivSRNFKtPixYtLfsxffPFF+vTpU7KuZ8+ejBs3jtWrV1NYWFhSw4Dgx/2ll14C4Pnnny8pb926NXPmzGHLli2sXbuWjz/+GAimWV+xYkXJubZt27bPe3VcdtllXHjhhVx55ZWV92Yrma4cr6K6ZjXgzcG9+f1JHRk79ydOeGgcr+XmadJEkUrSqVMnRo8eTffu3Vm1ahXXXXddybqsrCzuuOMOevXqxQknnEDnzp1p0KABACNHjuSxxx7jiCOOYO3atSX7tGrVivPPP5/u3btz8cUXc9hhhwFBP8Srr77KrbfeyqGHHkqPHj34/PPP9xrXxRdfzOrVq0tuY1sVaZLDamD+8g3c+tpMchetDi4gPLsrLRvVi3dYIuVSXSY53LBhAykpKRQWFnL22Wdz1VVXcfbZZ++2XUpKChs2bKi087766qu8+eab/Pvf/660Y+6JJjms4To0TeH//eYo/nxmF6YuXEX/EeMZ/flCTZooEkPDhg2jR48edO3albZt23LWWWeVvlMF3XDDDdx222386U9/ivm5KkI1jmomb/Um7nhjNuO/W0FO60bcf053OjSt/CtDRWKlutQ4qorrr7+eiRMn7lQ2ZMiQCveBVKTGoSvNqpmWjeox+sojeH3ajwx/Zw6njvyMISdkM+iYdiQnqgIp1YO773Fkkuzuscceq/RjVrTCoF+aasjMOOfwlnw09FhO6NyU//vwWwY8OpHZP64tfWeROKtTpw4rV67UQI84cXdWrlxJnTp1yn0MNVXVAB/MXsaf3pzNqo1bGXRMO4Ycn02d5MR4hyWyR9u2bSMvL6/kOgfZ/+rUqUPLli13uyq9rE1VShw1xNpN27j3vTm8MjWPdhn1+cu53TmiTeN4hyUi1YhGVR1gGtRL5oFzD+W5q3uxtWg75/1jEv/z5mw2bKk+M26KSPWgxFHD9MnOYMzNx3BV77b8e/Ii+j80jk+/XV76jiIiZaTEUQPVq5XE/5zRmVevPZr6tZO48pkvGfryV6zeuDXeoYlIDaDEUYMd3roR79zYhxuP68BbM5ZywkPjeGfmUo1mEZEKUeKo4WonJTK0f0fevqEPWY3qMviF6Qz6dy4/rdOIFhEpHyWOA0SnzDRev+5o7jj1EMZ/t4ITHhrHy18uVu1DRKKmxHEASUpMYNAx7fnwpmPonJnGra/N4uJ/fsHilZviHZqIVCNKHAegNhn1efHXR/K/Z3djZt5a+j88jn9+9gNFmjRRRMpAieMAlZBgXNTrIMYOPYbe7TO45925nPP453z30/p4hyYiVZwSxwEus0Fd/nl5DiMv6MHiVZs47ZHPGPnRPLYWbi99ZxE5IClxCGbGgB5ZjL35GE7tlsmIj77jjL9NYMaSNfEOTUSqICUOKZGeUpuRFxzG05fnsPbnbZz994nc++4cft5aFO/QRKQKUeKQ3RzfqRljhh7DhT0P4qnPFnDSw+P5/PuCeIclIlWEEofsUVqdZO49uxsvDTqSBIOLnvqC21+fxbrN2+IdmojEmRKH7NOR7dJ5f8gx/OaYdrz85WJOfGgcH835Kd5hiUgcKXFIqerWSuT2Uzvxn+t706heLa55dio3vDidgg1b4h2aiMSBEoeUWfeWDXlrcB9+d+LBfDh7GSc+NI7/TP9R05aIHGCUOCQqtZISuOH4bN69sQ9tMupz08tfcfXoqSxd83O8QxOR/USJQ8olu1kqr157NP9zemcmfb+S/iPG89zkRWzXtCUiNZ4Sh5RbYoJxVZ+2jLn5GHq0asid/5nNBU9NZkHBxniHJiIxpMQhFdaqcT3+fXVPHji3O9/kr+Pkh8fzj3HfU1ikaUtEaqKYJw4zSzSz6Wb2Trjc1sy+MLN5ZvaymdUKy2uHy/PD9W0ijnF7WP6tmZ0U65glembG+Tmt+GjosfTr2IT73/+Gs/4+kTlL18U7NBGpZPujxjEEmBux/BdghLtnA6uBq8Pyq4HV7t4BGBFuh5l1Bi4AugAnA383s8T9ELeUQ9O0OjxxaQ6PX/wLlq3dwpmPTuCvY75lS6GmLRGpKWKaOMysJXAa8M9w2YDjgFfDTUYDZ4WvB4TLhOuPD7cfALzk7lvcfQEwH+gZy7il4k7plslHQ49hQI8s/vbJfE4d+Rm5i1bFOywRqQSxrnE8DPwBKG7sTgfWuHthuJwHZIWvs4AlAOH6teH2JeV72KeEmQ0ys6lmNnXFihWV/T6kHBrWq8Vfzz+U0Vf1ZPO27Zz7j0kMe+trNm4pLH1nEamyYpY4zOx0YLm750YW72FTL2XdvvbZUeD+pLvnuHtOkyZNoo5XYufYg5vw4c3HcPlRbRg9aSH9R4xn/HdK7iLVVSxrHL2BM81sIfASQRPVw0BDM0sKt2kJLA1f5wGtAML1DYBVkeV72EeqiZTaSQw7swv/7zdHUTs5gcv+NYVb/t8M1m7SpIki1U3MEoe73+7uLd29DUHn9ifufjHwKXBuuNnlwJvh67fCZcL1n3gwl8VbwAXhqKu2QDYwJVZxS2zltGnMezf2ZfAvO/DG9B85YcQ4PpidH++wRCQKpSYOM2tvZrXD1/3M7EYza1iBc94KDDWz+QR9GE+H5U8D6WH5UOA2AHf/GngFmAN8AFzv7hqiU43VSU7klpM68tbg3jRNrc21z03juudyWb5+c7xDE5EysNImqDOzr4AcoA3wIUENoKO7nxrz6MopJyfHp06dGu8wpAwKi7bz1GcLGPHRd9RNTuTO0zpx7uEtCQbUicj+ZGa57p5T2nZlaaraHo5yOht42N1vBjIrGqAIQFJiAtf1a88HQ/rSsVkqv391Jpf9awpLVm2Kd2gishdlSRzbzOxCgv6Hd8Ky5NiFJAeidk1SeGnQkdx9VlemLVrNSQ+PZ9TEBRRp0kSRKqcsieNK4CjgXndfEHZQPxfbsORAlJBgXHpka8YMPZaebRsz7O05nP/EJOYvXx/v0EQkQql9HNWR+jiqP3fnP1/9yPC357BxSxHnHJ5F16wGdM5Mo2PzVOrVSir9ICISlbL2cez1f5+ZzWIPF9oVc/fu5YxNpFRmxtmHtaRvdhPufXcu78zI58UpS8J10Da9Pp0y0+iUmRo+p5HZoI461UX2g3392XZ6+Hx9+Pzv8PliQD2Xsl9kpNRmxMAeuDt5q39mbv465uavZ27+Omb9uJZ3Z+24BqRhvWQOaZ5K58wGJQklu1kKtZM0J6ZIZSrLcNyJ7t67tLKqRE1VB471m7fx7bIgkcwJE8q3y9bz87bgUp+kBKN9k5SdaiadMtNoklo7zpGLVD0VbqqKUN/M+rj7hPDARwP1KxqgSGVIrZNMTpvG5LRpXFJWtN1ZtHIjc/PXMyd/LXPz1/PFglX856sdM9VkpNSmc4ugqatzmEzaZdQnKVH3NhMpTVkSx9XAv8ysQbi8BrgqdiGJVExigtGuSQrtmqRwWvcdlxyt3riVuct2NHXNzV/HMxNWsjW8U2GtpAQObpZCp+Y7aiadM9NoUE+jz0UilXlUlZmlhduvjW1IFaemKimrbUXb+WHFxpKaSXFCKdiwtWSbrIZ1d2vqat24HgkJ6oiXmqXSmqrCearOIZhyJKl41Iq7D69gjCJxl5yYQMfmqXRsnsrZh+0oX75+806JZM7SdXz67YqSCxLr1UqkY/PUnWomhzRPpX5tDROWmq8s/8rfJLipUi6wJbbhiFQNTVPr0DS1DscevOPeLpu3FTHvpw1hR3yQUN6ZsZQXvlgMBMOEWzeut1PNpFNmKlkN62qYsNQoZUkcLd395JhHIlLF1UlOpFvLBnRr2aCkzN1ZunYzc5fuSCZz89fxwdfLKG4FTquTxCFhraS4Iz67WQp1kjVMWKqnsiSOz82sm7vPink0ItWMmZHVsC5ZDetyQudmJeUbtxTyzbIdTV1z89fxytQlbNoaDBNOTDDaZdTfqWbSORwmrNqJVHVlSRx9gCvMbAFBU5UBrivHRfaufu0kDm/diMNbNyop277dWbxq005NXbmLVvPWjB3DhNPr19qRSFoESaV9kxSSNUxYqpCyJI5TYh6FyAEgIcFok1GfNhn1OaXbjmHCazdtC4cJryu5Mn70pEVsLQyHCScm0KFpyk41k06ZaTSqXyteb0UOcGUajmtmhwJ9w8XP3H1GTKOqIA3HlequsGg7PxRsjKidBM1eK9bvGJ/SPK1OyUWMxU1ebdLrk6hhwlJOlTkcdwjwa+D1sOg5M3vS3f9WwRhFZC+SEhM4uFkqBzdLZUCPrJLygg1bdhoiPDd/PeO/W0FhOEy4bnIiBzdPpXNEMjmkeSqpdXQRo1SessxVNRM4yt03hsv1gUlVuY9DNQ45kGwp3DFMuOTak2XrWLNpW8k2BzWut1PNpHNmGi0baZiw7Kwy56oyoChiuSgsE5EqoHZSIl2zGtA1a+dhwsvWbd6pZjI3fx1j5vxUMkw4tXYSh+xyRXzHZqnUraVhwrJvZUkczwBfmNkb4fJZwNOxC0lEKsrMyGxQl8wGdTnukB3DhDdtLQxnE94xVPj1aT+yYcsiABIM2kYMEy7uiG+WpmHCskNZO8d/QTAs14Dx7j491oFVhJqqRMpu+3ZnyeriYcI7Ekre6p9LtmlUL3mnmknnzDQ6NE2hVpKGCdckldk5fiTwtbtPC5dTzayXu39RCXGKSJwlJBit0+vTOr0+J3fdMUx43eZtfBM5X1f+Op6bvIgtEcOED2/diD7ZGfTpkEHXrAYa0XWAKEvn+HTgFx5uaGYJwFR3/8V+iK9cVOMQiY3Cou0sXLmROfnrmblkDRO/X8nc/HUANKibzNHt00sSSet03banuqnUznGPyC7uvt3MNAWoyAHULQdGAAARv0lEQVQoKTGBDk1T6dA0lTMPbQEEQ4Qnzi9gwrwCJswv4P3ZywBo1bgufTpk0KdDE45un64LFmuQsiSAH8zsRuDxcPm3wA+xC0lEqpOMlNoM6JHFgB5ZuDs/FGwsSSTvzMjnxSlLMIOuLRrQu0MGfbMzOLx1I03yWI2VpamqKfAIcBzgwMfATe6+PPbhlY+aqkSqhsKi7czIW1uSSKYtXk3hdqd2UgI92zamd4egWatzZppujFUFlLWpqsx3AKxOlDhEqqaNWwr5YsFKJsxbyYT5K/jupw0ANK5fK+gf6ZBBn+wMWjaqF+dID0yVOarqYIJmqmbu3tXMugNnuvs9lRCniBxA6tdO4rhDmpVcW7J83WYmzA/6RibMK+CdmflAcC1J7w5BIjmqfQYN6mrKlKqkLE1V44DfA0+4+2Fh2Wx377of4isX1ThEqh93Z/7yDXw2r4CJ8wuY/MNKNm4tIsGgW8uG9A1rI4cd1JDaSeofiYXKHFVVz92n7HLVaGEZAqgDjAdqh+d51d3vMrO2wEtAY2AacKm7bw3vbf4scDiwEhjo7gvDY90OXE0w3cmN7v5hGeIWkWrEzMhulkp2s1Su6tOWrYXb+WrJmrA2soLHx33Po5/Op25yIr3aNS5p1urYLFVXte9nZUkcBWbWnqBjHDM7F8gvw35bgOPcfYOZJQMTzOx9YCgwwt1fMrN/ECSEx8Pn1e7ewcwuAP4CDDSzzsAFQBegBfCRmR3s7kV7OqmI1Ay1wg70nm0bM/TEg1m3eRuTv1/JxPkFfDa/gHvenQsEo7r6dEgPOtqzM8hsUDfOkdd8ZUkc1wNPAoeY2Y/AAuCS0nYKr/3YEC4mhw8nGJ11UVg+GhhGkDgGhK8BXgUeteDPiAHAS+6+BVhgZvOBnsCkMsQuIjVEWp1k+ndpTv8uzQFYuuZnJswPmrUmzC/gP18Fd1Js36Q+fbOb0LtDBke2a6wp5WOg1MTh7j8AJ4TTqSe4+/qyHtzMEoFcoAPwGPA9sMbdi5u68oDimw1kAUvCcxaa2VogPSyfHHHYyH0izzUIGARw0EEHlTVEEammWjSsy/k5rTg/pxXbtzvf/rS+5CLEl75czKjPF5KYYPRo1ZA+4fUjh7ZqqNvwVoKy3sjpGWA98FQ44eFt7j6mtH3D5qQeZtYQeAPotKfNik+1l3V7K9/1XE8S1IzIycmpeWOMRWSvEhKsZALGXx/Tji2FRUxbtIYJ81cwYf5K/vbJPEZ+PI+U2kkc2a5xyYWI7ZukqH+kHMrSVHWVu480s5OApsCVBImk1MRRzN3XmNl/gSOBhmaWFNY6WgJLw83ygFZAXjilSQNgVUR5sch9RER2UzspkaPap3NU+3R+f1JwX/fPvy8oGfr70dzg+uXmaXXCvpGgj6Rpap04R149lPVGTgCnAs+4+wwrQ4o2sybAtjBp1AVOIOjw/hQ4l2Bk1eXAm+Eub4XLk8L1n7i7m9lbwAtm9hBB53g2MKWsb1BEpEG9ZE7plskp3YLZf5es2lSSRD755idem5YHQMdmqSWTNPZq15h6tTQt356U5TqOZwj6FNoChwKJwH/d/fBS9utO0PmdCCQAr7j7cDNrx47huNOBS9x9Szh899/AYQQ1jQvC/hXM7I/AVQTDgG9y9/f3dW5dxyEiZbV9uzMnf13J9SNTFq5ia+F2khONww5qRN8OGfTOzqB7VgOSanj/SKVNORJOo94D+CGsPaQDWe4+s3JCrXxKHCJSXpu3FTF14Wo+m7+CifMLmP1jMG18ap0kjmqXTt/sDPpkN6FNer0a1z+iuaqUOESkEqzauJWJ4bDfz+YV8OOa4M6IWQ2DaeN7Z2fQu3066Sm14xxpxSlxKHGISCVzdxat3MRn8wuYOK+Az78vYN3m4OqCzplp9M3OoHeHDHq2bVwtp41X4lDiEJEYK9ruzPpxLRPmrWDC/AJyF61mW5FTKymBnIjb6nZpUT1uq1upiSO8kK8ZEaOw3H1xhSKMISUOEYmHTVsLmbJgVcmFiN8sC66XblgvvK1uhyb0zc6gVeOqOW18ZU6rfgNwF/ATsD0sdqB7hSIUEalh6tVKol/HpvTr2BSA5es3M+n7lXw2L5g2/r1ZwW11D2pcr6Q2cnT7dBrWq1631S3LqKr5QC93X7l/Qqo41ThEpKpxd75fsbGkk33yDyvZsKUQM+iW1SC8P3sGh7dpFLdp4ytzOO6nwIkR80tVeUocIlLVbSvazsy8NSXXj0xfvIbC7U6d5ASOaNO4pKO9U/P9d1vdykwcTwMdgXcJpkoHwN0fqmiQsaLEISLVzYYthXzxw8qSRDJveTC5eHr9WhzdIaPkQsSshrGbNr4yb+S0OHzUCh8iIlLJUmoncXynZhzfKbit7rK1m0umjJ8wv4C3ZwRT9LXLqF9y75Gj2qeTFodp4zUcV0SkinN3vvtpA5/NC65m/2LBKjaFt9U9tFVwW93eHTI47KBG1Eoq/7QoFW6qMrOH3f0mM3ubPU9jfma5o4sxJQ4Rqcm2Fm5n+uLVJbWRGUvWsN2hXq1ELup5EHee3rlcx62Mpqp/h88PlisCERGJiVpJCfRql06vdun8rn9H1v68jck/rGTCvAKyGsX+1rlqqhIREaDsNY6aPUewiIhUOiUOERGJSpkTh5nVj2UgIiJSPZSaOMzsaDObA8wNlw81s7/HPDIREamSylLjGAGcBKwEcPcZwDGxDEpERKquMjVVufuSXYqKYhCLiIhUA2WZcmSJmR0NuJnVAm4kbLYSEZEDT1lqHNcC1wNZQB7QI1wWEZEDUKk1DncvAC7eD7GIiEg1UJY7ALYFbgDasPOtY6vsXFUiIhI7Zenj+A/wNPA2O24dKyIiB6iyJI7N7v5IzCMREZFqoSyJY6SZ3QWMYec7AE6LWVQiIlJllSVxdAMuBY5jR1OVh8siInKAKUviOBto5+5bYx2MiIhUfWW5jmMG0DDWgYiISPVQlhpHM+AbM/uSnfs4NBxXROQAVJbEcVd5DmxmrYBngeYEfSNPuvtIM2sMvExwXchC4Hx3X21mBowETgU2AVcUd8Cb2eXAneGh73H30eWJSUREKq4sV46PK+exC4Hfufs0M0sFcs1sLHAF8LG7329mtwG3AbcCpwDZ4aMX8DjQK0w0dwE5BJ3yuWb2lruvLmdcIiJSAXvt4zCzCeHzejNbF/FYb2brSjuwu+cX1xjcfT3BxIhZwACguMYwGjgrfD0AeNYDk4GGZpZJMKX7WHdfFSaLscDJ5Xq3IiJSYfuqcdQHcPfUip7EzNoAhwFfAM3cPT88dr6ZNQ03ywIip2/PC8v2Vr7rOQYBgwAOOuigioYsIiJ7sa9RVV4ZJzCzFOA14CZ331dNxfYSw97Kdy5wf9Ldc9w9p0mTJuULVkRESrWvGkdTMxu6t5Xu/lBpBzezZIKk8by7vx4W/2RmmWFtIxNYHpbnAa0idm8JLA3L++1S/t/Szi0iIrGxrxpHIpACpO7lsU/hKKmngbm7JJm3gMvD15cDb0aUX2aBI4G1YZPWh0B/M2tkZo2A/mGZiIjEwb5qHPnuPrwCx+5NMFXJLDP7Kiy7A7gfeMXMrgYWA+eF694jGIo7n2A47pUA7r7KzO4Gvgy3G+7uqyoQl4iIVMC+Esee+hbKzN0n7OMYx+9he2cvdxZ0938B/6pIPCIiUjn21VS124+7iIjIXhOHmoNERGRPyjLJoYiISAklDhERiYoSh4iIREWJQ0REoqLEISIiUVHiEBGRqChxiIhIVJQ4REQkKkocIiISFSUOERGJihKHiIhERYlDRESiosQhIiJRUeIQEZGoKHGIiEhUlDhERCQqShwiIhIVJQ4REYmKEoeIiERFiUNERKKixCEiIlFR4hARkagocYiISFSUOEREJCpKHCIiEhUlDhERiYoSh4iIRCVmicPM/mVmy81sdkRZYzMba2bzwudGYbmZ2SNmNt/MZprZLyL2uTzcfp6ZXR6reEVEpGxiWeMYBZy8S9ltwMfung18HC4DnAJkh49BwOMQJBrgLqAX0BO4qzjZiIhIfMQscbj7eGDVLsUDgNHh69HAWRHlz3pgMtDQzDKBk4Cx7r7K3VcDY9k9GYmIyH60v/s4mrl7PkD43DQszwKWRGyXF5btrXw3ZjbIzKaa2dQVK1ZUeuAiIhKoKp3jtocy30f57oXuT7p7jrvnNGnSpFKDExGRHfZ34vgpbIIifF4elucBrSK2awks3Ue5iIjEyf5OHG8BxSOjLgfejCi/LBxddSSwNmzK+hDob2aNwk7x/mGZiIjESVKsDmxmLwL9gAwzyyMYHXU/8IqZXQ0sBs4LN38POBWYD2wCrgRw91VmdjfwZbjdcHfftcNdRET2I3PfY5dBtZaTk+NTp06NdxgiItWKmeW6e05p21WVznEREakmlDhERCQqShwiIhIVJQ4REYmKEoeIiERFiUNERKKixCEiIlFR4hARkagocYiISFSUOEREJCpKHCIiEhUlDhERiYoSh4iIREWJQ0REoqLEISIiUVHiEBGRqChxiIhIVJQ4REQkKkocIiISlaR4B1DlvH8bLJsV7yhERMqneTc45f6YnkI1DhERiYpqHLuKcaYWEanuVOMQEZGoKHGIiEhUlDhERCQqShwiIhIVJQ4REYmKEoeIiERFiUNERKKixCEiIlExd493DJXOzFYAiypwiAygoJLCkcqh76Tq0XdSNVXke2nt7k1K26hGJo6KMrOp7p4T7zhkB30nVY++k6ppf3wvaqoSEZGoKHGIiEhUlDj27Ml4ByC70XdS9eg7qZpi/r2oj0NERKKiGoeIiERFiUNERKKixBEys1Zm9qmZzTWzr81sSLxjEjCzOmY2xcxmhN/Ln+MdkwTMLNHMppvZO/GORQJmttDMZpnZV2Y2NVbn0R0AdygEfufu08wsFcg1s7HuPifegR3gtgDHufsGM0sGJpjZ++4+Od6BCUOAuUBavAORnfzS3WN6YaZqHCF3z3f3aeHr9QT/IbLiG5V4YEO4mBw+NKIjzsysJXAa8M94xyL7nxLHHphZG+Aw4Iv4RiJQ0iTyFbAcGOvu+l7i72HgD8D2eAciO3FgjJnlmtmgWJ1EiWMXZpYCvAbc5O7r4h2PgLsXuXsPoCXQ08y6xjumA5mZnQ4sd/fceMciu+nt7r8ATgGuN7NjYnESJY4IYRv6a8Dz7v56vOORnbn7GuC/wMlxDuVA1xs408wWAi8Bx5nZc/ENSQDcfWn4vBx4A+gZi/MocYTMzICngbnu/lC845GAmTUxs4bh67rACcA38Y3qwObut7t7S3dvA1wAfOLul8Q5rAOemdUPB/ZgZvWB/sDsWJxLo6p26A1cCswK29MB7nD39+IYk0AmMNrMEgn+0HnF3TX8U2R3zYA3gr+BSQJecPcPYnEiTTkiIiJRUVOViIhERYlDRESiosQhIiJRUeIQEZGoKHGIiEhUlDhEysHM3Mz+GrF8i5kNi/IYG0rfSqTqUeIQKZ8twK/MLCPegYjsb0ocIuVTSHBv55t3XWFmrc3sYzObGT4fFJa3NbNJZvalmd29yz6/D8tnFt9zJLwS+N3wXiSzzWzg/nhjIqVR4hApv8eAi82swS7ljwLPunt34HngkbB8JPC4ux8BLCve2Mz6A9kE8wr1AA4PJ6c7GVjq7oe6e1cgJlcBi0RLV46LlIOZbXD3FDMbDmwDfgZS3H2YmRUAme6+LZw4M9/dM8xsJdA8LE8jSAopZvYgcC6wJjx8CnAf8BnwIfAK8I67f7af36bIHmmuKpGKeRiYBjyzj218L6+LGXCfuz+x2wqzw4FTgfvMbIy7D69IsCKVQU1VIhXg7qsIagRXRxR/TjBrLMDFwITw9cRdyot9CFwV3gsGM8sys6Zm1gLY5O7PAQ8Cv4jNuxCJjmocIhX3V2BwxPKNwL/M7PfACuDKsHwI8IKZDSG47wsA7j7GzDoBk8KZTTcAlwAdgP8zs+0EzWHXxfqNiJSF+jhERCQqaqoSEZGoKHGIiEhUlDhERCQqShwiIhIVJQ4REYmKEoeIiERFiUNERKLy/wGMvFy2GBwYogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The following is a plot of time vs number of nodes for linear regression performed in pyspark ml as well as bigquery ml\n",
    "## For pyspark ml, the time requirements across different nodes has been shown. For bigquery ml, the yellow line is a \n",
    "## reference line for comparison.\n",
    "plt.title(\"Graph comparing Speeds\")\n",
    "plt.plot([2,3,4,5], [timediff_2nodes, timediff_3nodes, timediff_4nodes, timediff_5nodes], label = \"spark_ml\")\n",
    "plt.plot([2,3,4,5], [timediff_bqml, timediff_bqml, timediff_bqml, timediff_bqml], label = \"bigquery_ml\")\n",
    "plt.legend(loc = \"upper_right\")\n",
    "plt.ylabel(\"Time in seconds\")\n",
    "plt.xlabel(\"Nodes\")\n",
    "plt.xticks(range(2,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above plot, one could infer that further increasing the number of nodes to perform pyspark ml could get the performance in terms of speed closer to BigQuery ML. However, this project is restricted to using at most 5 nodes because of google cloud permission issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 SIMILARITIES\n",
    "\n",
    "- Both models suggest a very low r sqaured value which means that most of the variance in the data is not explained by the explanatory variables. \n",
    "- The parameters in both models are the same (regularisation parameter, L2 regularisation) to achieve similar results in terms of **accuracy and prediction**. \n",
    "- Initially the size of the dataset is 40.43 GB. For simplicity's sake, I removed all null values from the interesting predictors. The size of the dataset after removing null values is 23.42 GB. More data cleaning resulted in the model being built on 5.04 GB of data which seems like a missed opportunity since so much of the data is missing. \n",
    "- Since the errors are high and the r2 values are low, linear regression does not seem to be a good model to fit on the data. Probably other machine learning techniques for regression might be more suited to predicting the trip cost in this case. As mentioned before, BigQuery ML is still in Beta phase and can only perform Linear and Logistic Regression at the moment, so for the purpose of this project, I have stuck with Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 DIFFERENCES\n",
    "\n",
    "- The speeds of both vary quite a lot. When performing machine learning in pyspark, it is possible to increase speed by increasing the number of nodes doing the computations. BigQuery is known for being lightening fast and in this case it proved that by performing the same machine learning task that took spark more than an hour at times (in case of 2 and 3 worker nodes) with the same parameters in a matter of a few minutes. \n",
    "\n",
    "- Pyspark ML is a lot more flexible than BigQuery ML.\n",
    "\n",
    "- BigQuery ML seems to be more of a 'black box' than Pyspark ML when it comes to coding out the models. Not much knowledge is needed when coding the model in BigQuery. It takes time to debug and actually perform standardisation and onehotencoding of the variables in Pyspark ML whereas BigQuery does these transformations under the hood. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 LIMITATIONS OF EACH \n",
    "**PYSPARK ML**\n",
    "- Much slower than BigQuery ML. \n",
    "- Need to manually specify that some variables need to be standardised and onehotencoded.\n",
    "\n",
    "\n",
    "**BigQuery ML**\n",
    "- Lightening fast results but still in Beta phase.\n",
    "- Not much control because of its 'black box' nature.\n",
    "\n",
    "After the initial enthusiasm about BigQuery ML, Google has been fairly quiet about the product and has only improved the documentation. Also, the fact that it is currently in Beta phase does not work in its favour. In order to remain competitive in today's world, technology needs to evolve fast and there were expectations that Google BigQuery ML would expand fast. Hopefully, in the near future, Google will address these issues.[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Extensions\n",
    "The models compared here are the Ordinary Least Squares models. The pyspark.ml does not have gradient descent functionality so for the case of BigQuery which by default performs batch gradient descent on large datasets has explicitly been set to perform normal linear regression. Perhaps LinearRegressionwithSGD from the pyspark.mllib library could be used to speed up the performance of the model and BigQuery could perform linear regression with its default option and these two models can be compared as an extension to this project. \n",
    "\n",
    "In this project, pyspark.ml has been used over pyspark.mllib because [24]:\n",
    "- It is newer than pyspark.mllib.\n",
    "- It has the pipeline feature.\n",
    "- It takes in dataframes rather than RDD's. Dataframe API's are more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Steps\n",
    "From the command line:\n",
    "- Delete bucket using `gsutil rm -r gs://sunz-bucket`\n",
    "- Delete cluster using `gcloud dataproc clusters delete sunz-cluster`\n",
    "\n",
    "From the BigQuery User Interface available from the Google Cloud Console, delete the datasets under the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. CONCLUSION\n",
    "\n",
    "This project aims at showing how to perform machine learning on big data using two platforms and at comparing the differences between Pyspark ML and BigQuery ML. BigQuery ML is lightening fast and much easier to use than Pyspark ML. However, with great speed comes loss of flexibility and understanding. BigQuery ML is like a black box because a lot of the machine learning processes happen under the hood. The accuracies of both models are comparable as all the paramters that are fed in are similar. Pyspark ML speeds up with addition of new nodes. Even at the maximum of 5 number of nodes used to perform Pyspark ML, it is much slower than BigQuery ML. \n",
    "\n",
    "The Linear Regression model is used in this project. The model evaluators such as the R2 score (low) and Mean Squared Errors (high) indicate a poor model. Since BigQuery ML is in its nascent stage and only supports Linear and Logsitic Regression at this stage, linear regression has been used. More sophisticated regression models for example, ensemble methods like random forests might be better algorithms to use for this dataset.\n",
    "\n",
    "One of the biggest gifts to analysts from Google, BigQuery ML has opened the world of machine learning to people who are not data scientists but have a fair knowledge of SQL. When BigQuery ML is released with full blown capabilities, it could replace a lot of the older machine learning platforms for big data due to its lightening fast speed. However, BigQuery ML is relatively expensive. One should weigh the costs of BigQuery ML, speed and flexibility requirements of their specific projects before deciding what platform to perform machine learning in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. REFERENCES\n",
    "\n",
    "[1] \"What is BigQuery?\", Google BigQuery Documentation, available at https://cloud.google.com/bigquery/what-is-bigquery\n",
    "\n",
    "[2] \"An Inside Look at Google BigQuery\", Google paper, available at https://cloud.google.com/files/BigQueryTechnicalWP.pdf\n",
    "\n",
    "[3] Holak, Brian. \"Google's BigQuery ML needs big changes to compete\", 08 April 2019, Blog Post, available at https://searchbusinessanalytics.techtarget.com/news/252461317/Googles-BigQuery-ML-needs-big-changes-to-compete\n",
    "\n",
    "[4] Newcomer, Eric. \"Uber Starts Charging What It Thinks Youre Willing to Pay\", 19 May 2017, Blog Post, available at https://www.bloomberg.com/news/articles/2017-05-19/uber-s-future-may-rely-on-predicting-how-much-you-re-willing-to-pay\n",
    "\n",
    "[5] \"Use the BigQuery connector with Spark\", Google Cloud Dataproc Documentation, available at https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example\n",
    "\n",
    "[6] \"Use Cloud Dataproc, BigQuery, and Apache Spark ML for Machine Learning \", Google Cloud Dataproc Documentation, available at https://cloud.google.com/dataproc/docs/tutorials/bigquery-sparkml\n",
    "\n",
    "[7] \"Community Areas in Chicago\", Wikipedia, The free Encyclopedia page, available at https://en.wikipedia.org/wiki/Community_areas_in_Chicago\n",
    "\n",
    "[8] Insight. \"Spark Pipelines: Elegant Yet Powerful\", 22 March 2016, Blog Post, available at https://blog.insightdatascience.com/spark-pipelines-elegant-yet-powerful-7be93afcdd42\n",
    "\n",
    "[9] Introduction to Pyspark, Chapter 3, Getting started with Machine Learning Pipelines, Datacamp Course, available at https://campus.datacamp.com/courses/introduction-to-pyspark/getting-started-with-machine-learning-pipelines?ex=1\n",
    "\n",
    "[10] Radescu, George S. \"Machine Learning with PySpark - Feature Selection using PCC\", 21 February 2018, Blog Post, available at https://blog.epigno.systems/2018/02/21/machine-learning-with-pyspark-feature-selection/\n",
    "\n",
    "[11] \"Linear Regression\", Wikipedia, The free Encyclopedia page, available at https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "[12] Radescu, George S. \"Machine Learning with PySpark - Linear Regression\", 18 February 2018, Blog Post, available at https://blog.epigno.systems/2018/02/18/machine-learning-with-pyspark-linear-regression/\n",
    "\n",
    "[13] \"Spark MLlib Linear Regression Example\", Instaclustr Documentation, available at https://www.instaclustr.com/support/documentation/apache-spark/spark-mllib-linear-regression-example/\n",
    "\n",
    "[14] Blog editor, Minitab. \"When Is It Crucial to Standardize the Variables in a Regression Model?\", Blog Post, 10 February 2016, available at https://blog.minitab.com/blog/adventures-in-statistics-2/when-is-it-crucial-to-standardize-the-variables-in-a-regression-model\n",
    "\n",
    "[15] Menon, Unnikrishnan. 19 January 2019, answer on the question \"What is one-hot encoding and when is it used in data science?\", Quora, 18 April 2015, available at  https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science\n",
    "\n",
    "[16] McDonald, Carol. \"Fast data processing pipeline for predicting flight delays using Apache APIs: Kafka, Spark Streaming and Machine Learning (part 1)\", Blog Post, available at https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/\n",
    "\n",
    "[17] \"Scaling clusters\", Google Cloud Dataproc Documentation, available at https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters\n",
    "\n",
    "[18] \"Use the BigQuery connector with Spark/ Reading and Writing Data From BigQuery\", Google Cloud Dataproc Documentation, available at https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example#reading_and_writing_data_from_bigquery\n",
    "\n",
    "[19] \"Loading JSON data from Cloud Storage\", Google BigQuery Documentation, available at https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#bigquery_load_table_gcs_json_autodetect-python\n",
    "\n",
    "[20] \"Getting started with BigQuery ML for data scientists\", Google BigQuery Documentation, available at https://cloud.google.com/bigquery/docs/bigqueryml-scientist-start\n",
    "\n",
    "[21] \"Using BigQuery ML to predict birth weight\", Google BigQuery Documentation, available at https://cloud.google.com/bigquery/docs/bigqueryml-natality\n",
    "\n",
    "[22] \"The CREATE MODEL Statement\", Google BigQuery Documentation, available at https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create\n",
    "\n",
    "[23] \"Pyplot tutorial\", Matplotlib, available at https://matplotlib.org/users/pyplot_tutorial.html\n",
    "\n",
    "[24] Yuqli. \"Pyspark ML vs MLLib\", 21 December 2017, Blog Post, available at http://yuqli.com/?p=2330\n",
    "\n",
    "[25] \"chicago_taxi_trips\", Google BigQuery Dataset, available at  https://console.cloud.google.com/bigquery?_ga=2.237940288.-1586404566.1547810022&project=sunayani&folder&organizationId&p=bigquery-public-data&d=chicago_taxi_trips&t=taxi_trips&page=table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
